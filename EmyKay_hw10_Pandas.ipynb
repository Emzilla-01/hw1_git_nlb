{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import mode\n",
    "#######################\n",
    "#Donlgi's shared print format\n",
    "np.set_printoptions(edgeitems=30, linewidth=100000, \n",
    "    formatter=dict(float=lambda x: \"%.3g\" % x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Compute and Find the number and position of missing values in iris dataâ€™s sepal length column. (And few missing values).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'19 nan rows'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'locations: (array([  4,  12,  17,  21,  35,  38,  51,  55,  59,  60,  65, 100, 103, 110, 128, 130, 143, 146, 147], dtype=int64),)...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris_data_na = np.genfromtxt(r\"https://raw.githubusercontent.com/ammishra08/MachineLearning/master/Datasets/iris.csv\", delimiter=',',\n",
    "                             dtype=float, encoding='utf-8', skip_header=1, usecols=[0],)\n",
    "\n",
    "iris_data_na[np.random.randint(150, size=20)] = np.nan\n",
    "\n",
    "whr = np.where(np.isnan(iris_data_na))\n",
    "\n",
    "display(f\"{sum(np.isnan(iris_data_na))} nan rows\")\n",
    "display(f\"locations: {whr}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Sort the Admission dataset array based on TOEFL Score column and GRE Score. Use separate code for both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'admissions data sorted by GRE score'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[430, 340, 115, 5, 5, 4.5, 9.06, 1, 0.95],\n",
       "       [385, 340, 113, 4, 5, 5, 9.74, 1, 0.96],\n",
       "       [144, 340, 120, 4, 4.5, 4, 9.92, 1, 0.97],\n",
       "       [85, 340, 115, 5, 4.5, 4.5, 9.45, 1, 0.94],\n",
       "       [82, 340, 120, 4, 5, 5, 9.5, 1, 0.96],\n",
       "       [203, 340, 120, 5, 4.5, 4.5, 9.91, 1, 0.97],\n",
       "       [26, 340, 120, 5, 4.5, 4.5, 9.6, 1, 0.94],\n",
       "       [285, 340, 112, 4, 5, 4.5, 9.66, 1, 0.94],\n",
       "       [34, 340, 114, 5, 4, 4, 9.6, 1, 0.9],\n",
       "       [48, 339, 119, 5, 4.5, 4, 9.7, 0, 0.89]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'admissions data sorted by TOEFL score'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[498, 330, 120, 5, 4.5, 5, 9.56, 1, 0.93],\n",
       "       [144, 340, 120, 4, 4.5, 4, 9.92, 1, 0.97],\n",
       "       [298, 320, 120, 3, 4, 4.5, 9.11, 0, 0.86],\n",
       "       [98, 331, 120, 3, 4, 4, 8.96, 1, 0.86],\n",
       "       [82, 340, 120, 4, 5, 5, 9.5, 1, 0.96],\n",
       "       [26, 340, 120, 5, 4.5, 4.5, 9.6, 1, 0.94],\n",
       "       [203, 340, 120, 5, 4.5, 4.5, 9.91, 1, 0.97],\n",
       "       [204, 334, 120, 5, 4, 5, 9.87, 1, 0.97],\n",
       "       [213, 338, 120, 4, 5, 5, 9.66, 1, 0.95],\n",
       "       [48, 339, 119, 5, 4.5, 4, 9.7, 0, 0.89]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "adm_data = np.genfromtxt(r\"https://raw.githubusercontent.com/ammishra08/MachineLearning/master/Datasets/Admission.csv\", delimiter=',', \n",
    "                           encoding='utf-8', skip_header=1)\n",
    "#cols=\"Serial No.,GRE Score,TOEFL Score,University Rating,SOP,LOR ,CGPA,Research,Chance of Admit\".split(',')\n",
    "#display(cols)\n",
    "\n",
    "adm_data_by_gre = adm_data[adm_data[:,1].argsort()][::-1] # https://stackoverflow.com/questions/2828059/sorting-arrays-in-numpy-by-column/2828121#2828121\n",
    "\n",
    "display(\"admissions data sorted by GRE score\")\n",
    "display(adm_data_by_gre[:10,:])\n",
    "\n",
    "adm_data_by_toefl = adm_data[adm_data[:,2].argsort()][::-1]\n",
    "display(\"admissions data sorted by TOEFL score\")\n",
    "display(adm_data_by_toefl[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) How to replace all missing values with 0, in a numpy array using Admission.csv and iris.csv?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'locations of nan values in iris_data_na created in question 1:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([  4,  12,  17,  21,  35,  38,  51,  55,  59,  60,  65, 100, 103, 110, 128, 130, 143, 146, 147], dtype=int64),)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'locations of nan values in iris_data_na after replacement:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'locations of 0 in iris_data_na after replacement:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([  4,  12,  17,  21,  35,  38,  51,  55,  59,  60,  65, 100, 103, 110, 128, 130, 143, 146, 147], dtype=int64),)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"locations of nan values in iris_data_na created in question 1:\")\n",
    "\n",
    "display(np.where(np.isnan(iris_data_na)))\n",
    "\n",
    "iris_data_na[np.isnan(iris_data_na)] = 0\n",
    "\n",
    "display(\"locations of nan values in iris_data_na after replacement:\")\n",
    "\n",
    "display(np.where(np.isnan(iris_data_na)))\n",
    "\n",
    "display(\"locations of 0 in iris_data_na after replacement:\")\n",
    "\n",
    "display(np.where(iris_data_na==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_data = np.genfromtxt(r\"https://raw.githubusercontent.com/ammishra08/MachineLearning/master/Datasets/Admission.csv\", delimiter=',', \n",
    "                           encoding='utf-8', skip_header=1)\n",
    "adm_data.shape\n",
    "adm_data[np.random.randint(0,500,size=100), np.random.randint(0,8, size=100)] = np.nan\n",
    "\n",
    "adm_nan_ixs = np.where(np.isnan(adm_data)) #adm_nan_ixs = np.transpose(np.where(np.isnan(adm_data)))\n",
    "\n",
    "#display(\"locations of nan values in adm_data:\")\n",
    "#display(adm_nan_ixs[:10]) #\n",
    "#display(adm_data[:adm_nan_ixs[9][0]+1]) # indexing for manual validation\n",
    "\n",
    "adm_data[np.isnan(adm_data)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. PANDAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Combine four series to form and create a Dataframe with name series_data. Use the\n",
    "Dataframe and perform following operations.\n",
    "\n",
    "a. Display first five rows and last five rows using pandas method\n",
    "\n",
    "b. Convert the index of a series into a column of a dataframe\n",
    "\n",
    "c. Drop the index column of the DataFrame.\n",
    "\n",
    "d. Display the frequency counts of unique items of a series data column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base=['a','b','c','d','e']\n",
    "\n",
    "s1= pd.Series(base)\n",
    "for i in range(2,6):\n",
    "    exec(f\"s{i} = pd.Series([c*{i} for c in base])\")\n",
    "\n",
    "df = pd.DataFrame([s1,s2,s3,s4,s5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       0      1      2      3      4\n",
       " 0      a      b      c      d      e\n",
       " 1     aa     bb     cc     dd     ee\n",
       " 2    aaa    bbb    ccc    ddd    eee\n",
       " 3   aaaa   bbbb   cccc   dddd   eeee\n",
       " 4  aaaaa  bbbbb  ccccc  ddddd  eeeee,\n",
       "        0      1      2      3      4\n",
       " 0      a      b      c      d      e\n",
       " 1     aa     bb     cc     dd     ee\n",
       " 2    aaa    bbb    ccc    ddd    eee\n",
       " 3   aaaa   bbbb   cccc   dddd   eeee\n",
       " 4  aaaaa  bbbbb  ccccc  ddddd  eeeee)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a\n",
    "\n",
    "df.head(), df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   df.reset_index()'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>aa</td>\n",
       "      <td>bb</td>\n",
       "      <td>cc</td>\n",
       "      <td>dd</td>\n",
       "      <td>ee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>aaa</td>\n",
       "      <td>bbb</td>\n",
       "      <td>ccc</td>\n",
       "      <td>ddd</td>\n",
       "      <td>eee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>aaaa</td>\n",
       "      <td>bbbb</td>\n",
       "      <td>cccc</td>\n",
       "      <td>dddd</td>\n",
       "      <td>eeee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>aaaaa</td>\n",
       "      <td>bbbbb</td>\n",
       "      <td>ccccc</td>\n",
       "      <td>ddddd</td>\n",
       "      <td>eeeee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      0      1      2      3      4\n",
       "0      0      a      b      c      d      e\n",
       "1      1     aa     bb     cc     dd     ee\n",
       "2      2    aaa    bbb    ccc    ddd    eee\n",
       "3      3   aaaa   bbbb   cccc   dddd   eeee\n",
       "4      4  aaaaa  bbbbb  ccccc  ddddd  eeeee"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"   df['column'] assignment\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>not_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>bb</td>\n",
       "      <td>cc</td>\n",
       "      <td>dd</td>\n",
       "      <td>ee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaa</td>\n",
       "      <td>bbb</td>\n",
       "      <td>ccc</td>\n",
       "      <td>ddd</td>\n",
       "      <td>eee</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaaa</td>\n",
       "      <td>bbbb</td>\n",
       "      <td>cccc</td>\n",
       "      <td>dddd</td>\n",
       "      <td>eeee</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaaaa</td>\n",
       "      <td>bbbbb</td>\n",
       "      <td>ccccc</td>\n",
       "      <td>ddddd</td>\n",
       "      <td>eeeee</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4  not_index\n",
       "0      a      b      c      d      e          0\n",
       "1     aa     bb     cc     dd     ee          1\n",
       "2    aaa    bbb    ccc    ddd    eee          2\n",
       "3   aaaa   bbbb   cccc   dddd   eeee          3\n",
       "4  aaaaa  bbbbb  ccccc  ddddd  eeeee          4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#b\n",
    "display(\"   df.reset_index()\",df.reset_index()) # not assigned\n",
    "df['not_index'] = pd.Series(df.index)\n",
    "display(\"   df['column'] assignment\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>bb</td>\n",
       "      <td>cc</td>\n",
       "      <td>dd</td>\n",
       "      <td>ee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaa</td>\n",
       "      <td>bbb</td>\n",
       "      <td>ccc</td>\n",
       "      <td>ddd</td>\n",
       "      <td>eee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaaa</td>\n",
       "      <td>bbbb</td>\n",
       "      <td>cccc</td>\n",
       "      <td>dddd</td>\n",
       "      <td>eeee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaaaa</td>\n",
       "      <td>bbbbb</td>\n",
       "      <td>ccccc</td>\n",
       "      <td>ddddd</td>\n",
       "      <td>eeeee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4\n",
       "0      a      b      c      d      e\n",
       "1     aa     bb     cc     dd     ee\n",
       "2    aaa    bbb    ccc    ddd    eee\n",
       "3   aaaa   bbbb   cccc   dddd   eeee\n",
       "4  aaaaa  bbbbb  ccccc  ddddd  eeeee"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c\n",
    "#del df['not_index']\n",
    "df.drop(['not_index'], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRE Score\n",
       "340     9\n",
       "339     3\n",
       "338     4\n",
       "337     2\n",
       "336     5\n",
       "335     4\n",
       "334     8\n",
       "333     4\n",
       "332     8\n",
       "331     9\n",
       "330     8\n",
       "329    10\n",
       "328     9\n",
       "327    17\n",
       "326    12\n",
       "325    15\n",
       "324    23\n",
       "323    13\n",
       "322    17\n",
       "321    17\n",
       "320    16\n",
       "319    12\n",
       "318    12\n",
       "317    15\n",
       "316    18\n",
       "315    13\n",
       "314    16\n",
       "313    12\n",
       "312    24\n",
       "311    16\n",
       "310    11\n",
       "309     9\n",
       "308    13\n",
       "307    10\n",
       "306     7\n",
       "305    11\n",
       "304    12\n",
       "303     5\n",
       "302     7\n",
       "301    11\n",
       "300    12\n",
       "299    10\n",
       "298    10\n",
       "297     6\n",
       "296     5\n",
       "295     5\n",
       "294     2\n",
       "293     1\n",
       "290     2\n",
       "Name: Serial No., dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d. Display the frequency counts of unique items of a series data column.\n",
    "\n",
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.SeriesGroupBy.nunique.html\n",
    "#https://stackoverflow.com/questions/38309729/count-unique-values-with-pandas-per-groups\n",
    "\n",
    "adm_df = pd.read_csv(r\"https://raw.githubusercontent.com/ammishra08/MachineLearning/master/Datasets/Admission.csv\")\n",
    "adm_df.groupby(\"GRE Score\")[\"Serial No.\"].nunique()[::-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) How to stack two series vertically and horizontally?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        a\n",
       "1        b\n",
       "2        c\n",
       "3        d\n",
       "0      one\n",
       "1      two\n",
       "2    three\n",
       "3     four\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1\n",
       "0  a    one\n",
       "1  b    two\n",
       "2  c  three\n",
       "3  d   four"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://www.geeksforgeeks.org/stack-two-pandas-series-vertically-and-horizontally/\n",
    "a, b = pd.Series(['a','b','c','d']), pd.Series(['one','two','three','four'])\n",
    "c = pd.concat([a,b], axis=0)\n",
    "display(c)\n",
    "d = pd.concat([a,b], axis=1)\n",
    "display(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) How to convert a numpy array to a Dataframe of given shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4\n",
       "0 NaN NaN NaN NaN NaN\n",
       "1 NaN NaN NaN NaN NaN\n",
       "2 NaN NaN NaN NaN NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def shape_to_df(width, height):\n",
    "    w = np.array([np.nan for i in range(width)])\n",
    "    df = pd.DataFrame([w for n in range(height)])\n",
    "    return(df)\n",
    "\n",
    "display(shape_to_df(5,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Find the index positions of items of series A in another series B using numpy.where() and pd.Index() methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 2], dtype=int64),)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = pd.Series([2,3,4,5])   #items to search for <-- Basepoint?\n",
    "B = pd.Series([0,2,9,4]) #searched series\n",
    "# searching a value if present in list (B)\n",
    "cond0 = lambda i : i in list(B)\n",
    "np.where([cond0(i) for i in A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__annotations__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__inv__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmul__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_accessors',\n",
       " '_add_comparison_methods',\n",
       " '_add_logical_methods',\n",
       " '_add_logical_methods_disabled',\n",
       " '_add_numeric_methods',\n",
       " '_add_numeric_methods_add_sub_disabled',\n",
       " '_add_numeric_methods_binary',\n",
       " '_add_numeric_methods_disabled',\n",
       " '_add_numeric_methods_unary',\n",
       " '_assert_can_do_op',\n",
       " '_assert_can_do_setop',\n",
       " '_assert_safe_casting',\n",
       " '_assert_take_fillable',\n",
       " '_attributes',\n",
       " '_can_hold_identifiers_and_holds_name',\n",
       " '_can_hold_na',\n",
       " '_can_reindex',\n",
       " '_check_indexing_error',\n",
       " '_cleanup',\n",
       " '_coerce_scalar_to_index',\n",
       " '_comparables',\n",
       " '_concat',\n",
       " '_constructor',\n",
       " '_convert_arr_indexer',\n",
       " '_convert_can_do_setop',\n",
       " '_convert_for_op',\n",
       " '_convert_index_indexer',\n",
       " '_convert_list_indexer',\n",
       " '_convert_listlike_indexer',\n",
       " '_convert_slice_indexer',\n",
       " '_convert_tolerance',\n",
       " '_default_dtype',\n",
       " '_defer_to_indexing',\n",
       " '_deprecations',\n",
       " '_dir_additions',\n",
       " '_dir_deletions',\n",
       " '_engine',\n",
       " '_engine_type',\n",
       " '_filter_indexer_tolerance',\n",
       " '_format_attrs',\n",
       " '_format_data',\n",
       " '_format_native_types',\n",
       " '_format_space',\n",
       " '_format_with_header',\n",
       " '_formatter_func',\n",
       " '_get_attributes_dict',\n",
       " '_get_engine_target',\n",
       " '_get_fill_indexer',\n",
       " '_get_fill_indexer_searchsorted',\n",
       " '_get_grouper_for_level',\n",
       " '_get_level_number',\n",
       " '_get_level_values',\n",
       " '_get_names',\n",
       " '_get_nearest_indexer',\n",
       " '_get_partial_string_timestamp_match_key',\n",
       " '_get_reconciled_name_object',\n",
       " '_get_string_slice',\n",
       " '_get_unique_index',\n",
       " '_get_values_for_loc',\n",
       " '_has_complex_internals',\n",
       " '_id',\n",
       " '_inner_indexer',\n",
       " '_invalid_indexer',\n",
       " '_is_comparable_dtype',\n",
       " '_is_compatible_with_other',\n",
       " '_is_memory_usage_qualified',\n",
       " '_is_numeric_dtype',\n",
       " '_is_strictly_monotonic_decreasing',\n",
       " '_is_strictly_monotonic_increasing',\n",
       " '_isnan',\n",
       " '_join_level',\n",
       " '_join_monotonic',\n",
       " '_join_multi',\n",
       " '_join_non_unique',\n",
       " '_join_precedence',\n",
       " '_left_indexer',\n",
       " '_left_indexer_unique',\n",
       " '_map_values',\n",
       " '_maybe_cast_indexer',\n",
       " '_maybe_cast_slice_bound',\n",
       " '_maybe_promote',\n",
       " '_mpl_repr',\n",
       " '_na_value',\n",
       " '_name',\n",
       " '_nan_idxs',\n",
       " '_no_setting_name',\n",
       " '_outer_indexer',\n",
       " '_reduce',\n",
       " '_reindex_non_unique',\n",
       " '_reset_cache',\n",
       " '_reset_identity',\n",
       " '_scalar_data_error',\n",
       " '_searchsorted_monotonic',\n",
       " '_set_names',\n",
       " '_shallow_copy',\n",
       " '_should_fallback_to_positional',\n",
       " '_simple_new',\n",
       " '_sort_levels_monotonic',\n",
       " '_string_data_error',\n",
       " '_summary',\n",
       " '_supports_partial_string_indexing',\n",
       " '_to_safe_for_reshape',\n",
       " '_transform_index',\n",
       " '_typ',\n",
       " '_union',\n",
       " '_union_incompatible_dtypes',\n",
       " '_validate_dtype',\n",
       " '_validate_index_level',\n",
       " '_validate_indexer',\n",
       " '_validate_names',\n",
       " '_validate_positional_slice',\n",
       " '_validate_sort_keyword',\n",
       " '_values',\n",
       " '_wrap_joined_index',\n",
       " '_wrap_setop_result',\n",
       " 'all',\n",
       " 'any',\n",
       " 'append',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'array',\n",
       " 'asi8',\n",
       " 'asof',\n",
       " 'asof_locs',\n",
       " 'astype',\n",
       " 'copy',\n",
       " 'delete',\n",
       " 'difference',\n",
       " 'drop',\n",
       " 'drop_duplicates',\n",
       " 'droplevel',\n",
       " 'dropna',\n",
       " 'dtype',\n",
       " 'duplicated',\n",
       " 'empty',\n",
       " 'equals',\n",
       " 'factorize',\n",
       " 'fillna',\n",
       " 'format',\n",
       " 'get_indexer',\n",
       " 'get_indexer_for',\n",
       " 'get_indexer_non_unique',\n",
       " 'get_level_values',\n",
       " 'get_loc',\n",
       " 'get_slice_bound',\n",
       " 'get_value',\n",
       " 'groupby',\n",
       " 'has_duplicates',\n",
       " 'hasnans',\n",
       " 'holds_integer',\n",
       " 'identical',\n",
       " 'inferred_type',\n",
       " 'insert',\n",
       " 'intersection',\n",
       " 'is_',\n",
       " 'is_all_dates',\n",
       " 'is_boolean',\n",
       " 'is_categorical',\n",
       " 'is_floating',\n",
       " 'is_integer',\n",
       " 'is_interval',\n",
       " 'is_mixed',\n",
       " 'is_monotonic',\n",
       " 'is_monotonic_decreasing',\n",
       " 'is_monotonic_increasing',\n",
       " 'is_numeric',\n",
       " 'is_object',\n",
       " 'is_type_compatible',\n",
       " 'is_unique',\n",
       " 'isin',\n",
       " 'isna',\n",
       " 'isnull',\n",
       " 'item',\n",
       " 'join',\n",
       " 'map',\n",
       " 'max',\n",
       " 'memory_usage',\n",
       " 'min',\n",
       " 'name',\n",
       " 'names',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'nlevels',\n",
       " 'notna',\n",
       " 'notnull',\n",
       " 'nunique',\n",
       " 'putmask',\n",
       " 'ravel',\n",
       " 'reindex',\n",
       " 'rename',\n",
       " 'repeat',\n",
       " 'searchsorted',\n",
       " 'set_names',\n",
       " 'shape',\n",
       " 'shift',\n",
       " 'size',\n",
       " 'slice_indexer',\n",
       " 'slice_locs',\n",
       " 'sort',\n",
       " 'sort_values',\n",
       " 'sortlevel',\n",
       " 'symmetric_difference',\n",
       " 'take',\n",
       " 'to_flat_index',\n",
       " 'to_frame',\n",
       " 'to_list',\n",
       " 'to_native_types',\n",
       " 'to_numpy',\n",
       " 'to_series',\n",
       " 'transpose',\n",
       " 'union',\n",
       " 'unique',\n",
       " 'value_counts',\n",
       " 'values',\n",
       " 'view',\n",
       " 'where']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#help(pd.Index(B))\n",
    "dir(pd.Index(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Index(B).get_indexer_non_unique(A)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) How to convert the first character of each Categorical value in a series to uppercase keeping rest of values to lowercase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            custID\n",
       "1          custName\n",
       "2           Country\n",
       "3           address\n",
       "4            Gender\n",
       "5          Ismember\n",
       "6    registeredDate\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colnames = pd.Series(['custID','custName','country', 'address', 'gender', 'ismember', 'registeredDate'])\n",
    "categorical_colnames = ['country', 'gender', 'ismember']\n",
    "\n",
    "#a='country'\n",
    "for i in colnames.iteritems():\n",
    "    if i[1] in categorical_colnames:\n",
    "        colnames[i[0]] = i[1].title()\n",
    "\n",
    "display(colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) How to filter valid emails from a series data using following pattern to be matched? pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         hello@world.com\n",
       "1    hello@whitehouse.gov\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pattern =r'[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,4}'\n",
    "\n",
    "series_data = pd.Series(['hello@world.com', 'good@bye@no@no', 'hello@whitehouse.gov', 'maybe at silly dot com'])\n",
    "\n",
    "r = re.compile(pattern)\n",
    "\n",
    "series_data = pd.Series([i for i in series_data if r.match(i)])\n",
    "\n",
    "series_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) Analysing earthquake data using url:\n",
    "https://raw.githubusercontent.com/ammishra08/MachineLearning/master/Datasets/earthquakes_2014.csv\n",
    "\n",
    "* a. Load the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>net</th>\n",
       "      <th>id</th>\n",
       "      <th>updated</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-31 23:53:37.000</td>\n",
       "      <td>60.252000</td>\n",
       "      <td>-152.708100</td>\n",
       "      <td>90.20</td>\n",
       "      <td>1.10</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2900</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak11155107</td>\n",
       "      <td>2014-02-05T19:34:41.515Z</td>\n",
       "      <td>26km S of Redoubt Volcano, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-31 23:48:35.452</td>\n",
       "      <td>37.070300</td>\n",
       "      <td>-115.130900</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.33</td>\n",
       "      <td>ml</td>\n",
       "      <td>4.0</td>\n",
       "      <td>171.43</td>\n",
       "      <td>0.342000</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn00436847</td>\n",
       "      <td>2014-02-01T01:35:09.000Z</td>\n",
       "      <td>32km S of Alamo, Nevada</td>\n",
       "      <td>earthquake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-31 23:47:24.000</td>\n",
       "      <td>64.671700</td>\n",
       "      <td>-149.252800</td>\n",
       "      <td>7.10</td>\n",
       "      <td>1.30</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak11151142</td>\n",
       "      <td>2014-02-01T00:03:53.010Z</td>\n",
       "      <td>12km NNW of North Nenana, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-31 23:30:54.000</td>\n",
       "      <td>63.188700</td>\n",
       "      <td>-148.957500</td>\n",
       "      <td>96.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0700</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak11151135</td>\n",
       "      <td>2014-01-31T23:41:25.007Z</td>\n",
       "      <td>22km S of Cantwell, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-31 23:30:52.210</td>\n",
       "      <td>32.616833</td>\n",
       "      <td>-115.692500</td>\n",
       "      <td>10.59</td>\n",
       "      <td>1.34</td>\n",
       "      <td>ml</td>\n",
       "      <td>6.0</td>\n",
       "      <td>285.00</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>ci</td>\n",
       "      <td>ci37171541</td>\n",
       "      <td>2014-02-01T00:13:20.107Z</td>\n",
       "      <td>10km WNW of Progreso, Mexico</td>\n",
       "      <td>earthquake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120103</th>\n",
       "      <td>2014-12-01 00:10:16.000</td>\n",
       "      <td>60.963900</td>\n",
       "      <td>-146.762900</td>\n",
       "      <td>14.80</td>\n",
       "      <td>3.80</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak11453391</td>\n",
       "      <td>2015-03-24T18:25:07.628Z</td>\n",
       "      <td>29km SW of Valdez, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120104</th>\n",
       "      <td>2014-12-01 00:09:39.000</td>\n",
       "      <td>58.869100</td>\n",
       "      <td>-154.415900</td>\n",
       "      <td>108.40</td>\n",
       "      <td>2.40</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak11453395</td>\n",
       "      <td>2014-12-10T01:04:25.209Z</td>\n",
       "      <td>102km SSE of Old Iliamna, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120105</th>\n",
       "      <td>2014-12-01 00:09:25.350</td>\n",
       "      <td>38.843498</td>\n",
       "      <td>-122.825836</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.43</td>\n",
       "      <td>md</td>\n",
       "      <td>8.0</td>\n",
       "      <td>107.00</td>\n",
       "      <td>0.008991</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc72358451</td>\n",
       "      <td>2014-12-01T01:15:02.814Z</td>\n",
       "      <td>9km WNW of Cobb, California</td>\n",
       "      <td>earthquake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120106</th>\n",
       "      <td>2014-12-01 00:05:54.000</td>\n",
       "      <td>65.152100</td>\n",
       "      <td>-148.992000</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0.40</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak11453390</td>\n",
       "      <td>2014-12-10T01:03:01.225Z</td>\n",
       "      <td>57km NW of Ester, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120107</th>\n",
       "      <td>2014-12-01 00:04:05.000</td>\n",
       "      <td>60.227200</td>\n",
       "      <td>-147.024500</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.60</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak11453389</td>\n",
       "      <td>2014-12-09T02:04:46.894Z</td>\n",
       "      <td>78km WSW of Cordova, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120108 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           time   latitude   longitude   depth   mag magType  \\\n",
       "0       2014-01-31 23:53:37.000  60.252000 -152.708100   90.20  1.10      ml   \n",
       "1       2014-01-31 23:48:35.452  37.070300 -115.130900    0.00  1.33      ml   \n",
       "2       2014-01-31 23:47:24.000  64.671700 -149.252800    7.10  1.30      ml   \n",
       "3       2014-01-31 23:30:54.000  63.188700 -148.957500   96.50  0.80      ml   \n",
       "4       2014-01-31 23:30:52.210  32.616833 -115.692500   10.59  1.34      ml   \n",
       "...                         ...        ...         ...     ...   ...     ...   \n",
       "120103  2014-12-01 00:10:16.000  60.963900 -146.762900   14.80  3.80      ml   \n",
       "120104  2014-12-01 00:09:39.000  58.869100 -154.415900  108.40  2.40      ml   \n",
       "120105  2014-12-01 00:09:25.350  38.843498 -122.825836    2.37  0.43      md   \n",
       "120106  2014-12-01 00:05:54.000  65.152100 -148.992000    9.50  0.40      ml   \n",
       "120107  2014-12-01 00:04:05.000  60.227200 -147.024500    2.50  1.60      ml   \n",
       "\n",
       "        nst     gap      dmin     rms net          id  \\\n",
       "0       NaN     NaN       NaN  0.2900  ak  ak11155107   \n",
       "1       4.0  171.43  0.342000  0.0247  nn  nn00436847   \n",
       "2       NaN     NaN       NaN  1.0000  ak  ak11151142   \n",
       "3       NaN     NaN       NaN  1.0700  ak  ak11151135   \n",
       "4       6.0  285.00  0.043210  0.2000  ci  ci37171541   \n",
       "...     ...     ...       ...     ...  ..         ...   \n",
       "120103  NaN     NaN       NaN  0.6900  ak  ak11453391   \n",
       "120104  NaN     NaN       NaN  0.6700  ak  ak11453395   \n",
       "120105  8.0  107.00  0.008991  0.0300  nc  nc72358451   \n",
       "120106  NaN     NaN       NaN  0.6900  ak  ak11453390   \n",
       "120107  NaN     NaN       NaN  0.7300  ak  ak11453389   \n",
       "\n",
       "                         updated                              place  \\\n",
       "0       2014-02-05T19:34:41.515Z  26km S of Redoubt Volcano, Alaska   \n",
       "1       2014-02-01T01:35:09.000Z            32km S of Alamo, Nevada   \n",
       "2       2014-02-01T00:03:53.010Z   12km NNW of North Nenana, Alaska   \n",
       "3       2014-01-31T23:41:25.007Z         22km S of Cantwell, Alaska   \n",
       "4       2014-02-01T00:13:20.107Z       10km WNW of Progreso, Mexico   \n",
       "...                          ...                                ...   \n",
       "120103  2015-03-24T18:25:07.628Z          29km SW of Valdez, Alaska   \n",
       "120104  2014-12-10T01:04:25.209Z   102km SSE of Old Iliamna, Alaska   \n",
       "120105  2014-12-01T01:15:02.814Z        9km WNW of Cobb, California   \n",
       "120106  2014-12-10T01:03:01.225Z           57km NW of Ester, Alaska   \n",
       "120107  2014-12-09T02:04:46.894Z        78km WSW of Cordova, Alaska   \n",
       "\n",
       "              type  \n",
       "0       earthquake  \n",
       "1       earthquake  \n",
       "2       earthquake  \n",
       "3       earthquake  \n",
       "4       earthquake  \n",
       "...            ...  \n",
       "120103  earthquake  \n",
       "120104  earthquake  \n",
       "120105  earthquake  \n",
       "120106  earthquake  \n",
       "120107  earthquake  \n",
       "\n",
       "[120108 rows x 15 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_df = pd.read_csv(\"https://raw.githubusercontent.com/ammishra08/MachineLearning/master/Datasets/earthquakes_2014.csv\")\n",
    "\n",
    "eq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* b. Convert time column from object to datetime format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2014-01-31 23:53:37.000\n",
       "1        2014-01-31 23:48:35.452\n",
       "2        2014-01-31 23:47:24.000\n",
       "3        2014-01-31 23:30:54.000\n",
       "4        2014-01-31 23:30:52.210\n",
       "                   ...          \n",
       "120103   2014-12-01 00:10:16.000\n",
       "120104   2014-12-01 00:09:39.000\n",
       "120105   2014-12-01 00:09:25.350\n",
       "120106   2014-12-01 00:05:54.000\n",
       "120107   2014-12-01 00:04:05.000\n",
       "Name: time, Length: 120108, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_df[\"time\"] = pd.to_datetime(eq_df[\"time\"])\n",
    "\n",
    "eq_df[\"time\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* c. Extract the latitude, longitude, depth, mag arrays to arrays Lat, Long, D, M column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I am having trouble understanding question c... is it to just create new columns with same values??? '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" I am having trouble understanding question c... is it to just create new columns with same values??? \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new columns:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['time', 'magType', 'nst', 'gap', 'dmin', 'rms', 'net', 'id', 'updated',\n",
       "       'place', 'type', 'Lat', 'Long', 'D', 'M'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>net</th>\n",
       "      <th>id</th>\n",
       "      <th>updated</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>D</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-31 23:53:37.000</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2900</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak11155107</td>\n",
       "      <td>2014-02-05T19:34:41.515Z</td>\n",
       "      <td>26km S of Redoubt Volcano, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>60.252000</td>\n",
       "      <td>-152.708100</td>\n",
       "      <td>90.20</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-31 23:48:35.452</td>\n",
       "      <td>ml</td>\n",
       "      <td>4.0</td>\n",
       "      <td>171.43</td>\n",
       "      <td>0.342000</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn00436847</td>\n",
       "      <td>2014-02-01T01:35:09.000Z</td>\n",
       "      <td>32km S of Alamo, Nevada</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>37.070300</td>\n",
       "      <td>-115.130900</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-31 23:47:24.000</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak11151142</td>\n",
       "      <td>2014-02-01T00:03:53.010Z</td>\n",
       "      <td>12km NNW of North Nenana, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>64.671700</td>\n",
       "      <td>-149.252800</td>\n",
       "      <td>7.10</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-31 23:30:54.000</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0700</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak11151135</td>\n",
       "      <td>2014-01-31T23:41:25.007Z</td>\n",
       "      <td>22km S of Cantwell, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>63.188700</td>\n",
       "      <td>-148.957500</td>\n",
       "      <td>96.50</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-31 23:30:52.210</td>\n",
       "      <td>ml</td>\n",
       "      <td>6.0</td>\n",
       "      <td>285.00</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>ci</td>\n",
       "      <td>ci37171541</td>\n",
       "      <td>2014-02-01T00:13:20.107Z</td>\n",
       "      <td>10km WNW of Progreso, Mexico</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>32.616833</td>\n",
       "      <td>-115.692500</td>\n",
       "      <td>10.59</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120103</th>\n",
       "      <td>2014-12-01 00:10:16.000</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak11453391</td>\n",
       "      <td>2015-03-24T18:25:07.628Z</td>\n",
       "      <td>29km SW of Valdez, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>60.963900</td>\n",
       "      <td>-146.762900</td>\n",
       "      <td>14.80</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120104</th>\n",
       "      <td>2014-12-01 00:09:39.000</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak11453395</td>\n",
       "      <td>2014-12-10T01:04:25.209Z</td>\n",
       "      <td>102km SSE of Old Iliamna, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>58.869100</td>\n",
       "      <td>-154.415900</td>\n",
       "      <td>108.40</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120105</th>\n",
       "      <td>2014-12-01 00:09:25.350</td>\n",
       "      <td>md</td>\n",
       "      <td>8.0</td>\n",
       "      <td>107.00</td>\n",
       "      <td>0.008991</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc72358451</td>\n",
       "      <td>2014-12-01T01:15:02.814Z</td>\n",
       "      <td>9km WNW of Cobb, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>38.843498</td>\n",
       "      <td>-122.825836</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120106</th>\n",
       "      <td>2014-12-01 00:05:54.000</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak11453390</td>\n",
       "      <td>2014-12-10T01:03:01.225Z</td>\n",
       "      <td>57km NW of Ester, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>65.152100</td>\n",
       "      <td>-148.992000</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120107</th>\n",
       "      <td>2014-12-01 00:04:05.000</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak11453389</td>\n",
       "      <td>2014-12-09T02:04:46.894Z</td>\n",
       "      <td>78km WSW of Cordova, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>60.227200</td>\n",
       "      <td>-147.024500</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120108 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          time magType  nst     gap      dmin     rms net  \\\n",
       "0      2014-01-31 23:53:37.000      ml  NaN     NaN       NaN  0.2900  ak   \n",
       "1      2014-01-31 23:48:35.452      ml  4.0  171.43  0.342000  0.0247  nn   \n",
       "2      2014-01-31 23:47:24.000      ml  NaN     NaN       NaN  1.0000  ak   \n",
       "3      2014-01-31 23:30:54.000      ml  NaN     NaN       NaN  1.0700  ak   \n",
       "4      2014-01-31 23:30:52.210      ml  6.0  285.00  0.043210  0.2000  ci   \n",
       "...                        ...     ...  ...     ...       ...     ...  ..   \n",
       "120103 2014-12-01 00:10:16.000      ml  NaN     NaN       NaN  0.6900  ak   \n",
       "120104 2014-12-01 00:09:39.000      ml  NaN     NaN       NaN  0.6700  ak   \n",
       "120105 2014-12-01 00:09:25.350      md  8.0  107.00  0.008991  0.0300  nc   \n",
       "120106 2014-12-01 00:05:54.000      ml  NaN     NaN       NaN  0.6900  ak   \n",
       "120107 2014-12-01 00:04:05.000      ml  NaN     NaN       NaN  0.7300  ak   \n",
       "\n",
       "                id                   updated  \\\n",
       "0       ak11155107  2014-02-05T19:34:41.515Z   \n",
       "1       nn00436847  2014-02-01T01:35:09.000Z   \n",
       "2       ak11151142  2014-02-01T00:03:53.010Z   \n",
       "3       ak11151135  2014-01-31T23:41:25.007Z   \n",
       "4       ci37171541  2014-02-01T00:13:20.107Z   \n",
       "...            ...                       ...   \n",
       "120103  ak11453391  2015-03-24T18:25:07.628Z   \n",
       "120104  ak11453395  2014-12-10T01:04:25.209Z   \n",
       "120105  nc72358451  2014-12-01T01:15:02.814Z   \n",
       "120106  ak11453390  2014-12-10T01:03:01.225Z   \n",
       "120107  ak11453389  2014-12-09T02:04:46.894Z   \n",
       "\n",
       "                                    place        type        Lat        Long  \\\n",
       "0       26km S of Redoubt Volcano, Alaska  earthquake  60.252000 -152.708100   \n",
       "1                 32km S of Alamo, Nevada  earthquake  37.070300 -115.130900   \n",
       "2        12km NNW of North Nenana, Alaska  earthquake  64.671700 -149.252800   \n",
       "3              22km S of Cantwell, Alaska  earthquake  63.188700 -148.957500   \n",
       "4            10km WNW of Progreso, Mexico  earthquake  32.616833 -115.692500   \n",
       "...                                   ...         ...        ...         ...   \n",
       "120103          29km SW of Valdez, Alaska  earthquake  60.963900 -146.762900   \n",
       "120104   102km SSE of Old Iliamna, Alaska  earthquake  58.869100 -154.415900   \n",
       "120105        9km WNW of Cobb, California  earthquake  38.843498 -122.825836   \n",
       "120106           57km NW of Ester, Alaska  earthquake  65.152100 -148.992000   \n",
       "120107        78km WSW of Cordova, Alaska  earthquake  60.227200 -147.024500   \n",
       "\n",
       "             D     M  \n",
       "0        90.20  1.10  \n",
       "1         0.00  1.33  \n",
       "2         7.10  1.30  \n",
       "3        96.50  0.80  \n",
       "4        10.59  1.34  \n",
       "...        ...   ...  \n",
       "120103   14.80  3.80  \n",
       "120104  108.40  2.40  \n",
       "120105    2.37  0.43  \n",
       "120106    9.50  0.40  \n",
       "120107    2.50  1.60  \n",
       "\n",
       "[120108 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from copy import copy\n",
    "relabel_to_from = [\n",
    "('Lat', 'latitude'),\n",
    "('Long', 'longitude'),\n",
    "('D', 'depth'),\n",
    "('M', 'mag'),    \n",
    "]\n",
    "\n",
    "for t in relabel_to_from:\n",
    "    eq_df[t[0]] = copy(eq_df[t[1]])\n",
    "    eq_df.drop([t[1]] , axis=1, inplace=True)\n",
    "\n",
    "display(\"new columns:\", eq_df.columns)\n",
    "\n",
    "display(eq_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* d. Mask out invalid data (the nan values from missing points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>net</th>\n",
       "      <th>id</th>\n",
       "      <th>updated</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>D</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-31 23:48:35.452</td>\n",
       "      <td>ml</td>\n",
       "      <td>4.0</td>\n",
       "      <td>171.430000</td>\n",
       "      <td>0.342000</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn00436847</td>\n",
       "      <td>2014-02-01T01:35:09.000Z</td>\n",
       "      <td>32km S of Alamo, Nevada</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>37.070300</td>\n",
       "      <td>-115.130900</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-31 23:30:52.210</td>\n",
       "      <td>ml</td>\n",
       "      <td>6.0</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>ci</td>\n",
       "      <td>ci37171541</td>\n",
       "      <td>2014-02-01T00:13:20.107Z</td>\n",
       "      <td>10km WNW of Progreso, Mexico</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>32.616833</td>\n",
       "      <td>-115.692500</td>\n",
       "      <td>10.59</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014-01-31 23:30:36.930</td>\n",
       "      <td>ml</td>\n",
       "      <td>16.0</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>0.080810</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>ci</td>\n",
       "      <td>ci11419722</td>\n",
       "      <td>2014-02-01T00:09:04.470Z</td>\n",
       "      <td>3km N of Tijuana, Mexico</td>\n",
       "      <td>quarry blast</td>\n",
       "      <td>32.567667</td>\n",
       "      <td>-117.013500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014-01-31 23:28:04.020</td>\n",
       "      <td>ml</td>\n",
       "      <td>26.0</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>ci</td>\n",
       "      <td>ci11419714</td>\n",
       "      <td>2014-02-01T00:54:07.630Z</td>\n",
       "      <td>11km N of Borrego Springs, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>33.359000</td>\n",
       "      <td>-116.360500</td>\n",
       "      <td>12.98</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2014-01-31 22:54:06.200</td>\n",
       "      <td>md</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100.799992</td>\n",
       "      <td>0.035933</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>nm</td>\n",
       "      <td>nm020414a</td>\n",
       "      <td>2014-02-04T14:10:26.871Z</td>\n",
       "      <td>6km SSW of Lilbourn, Missouri</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>36.538300</td>\n",
       "      <td>-89.629000</td>\n",
       "      <td>7.80</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120092</th>\n",
       "      <td>2014-12-01 01:02:27.710</td>\n",
       "      <td>md</td>\n",
       "      <td>13.0</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>0.121400</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc72358476</td>\n",
       "      <td>2014-12-03T17:30:04.727Z</td>\n",
       "      <td>25km SE of Mammoth Lakes, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>37.473333</td>\n",
       "      <td>-118.786333</td>\n",
       "      <td>5.92</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120093</th>\n",
       "      <td>2014-12-01 01:00:29.200</td>\n",
       "      <td>md</td>\n",
       "      <td>26.0</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>0.033850</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc72358466</td>\n",
       "      <td>2014-12-11T06:55:03.683Z</td>\n",
       "      <td>11km ESE of Cloverdale, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>38.767167</td>\n",
       "      <td>-122.888333</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120094</th>\n",
       "      <td>2014-12-01 00:59:41.910</td>\n",
       "      <td>md</td>\n",
       "      <td>7.0</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>0.008552</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc72358461</td>\n",
       "      <td>2014-12-01T01:33:06.454Z</td>\n",
       "      <td>8km NW of The Geysers, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>38.830166</td>\n",
       "      <td>-122.833504</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120095</th>\n",
       "      <td>2014-12-01 00:58:43.430</td>\n",
       "      <td>ml</td>\n",
       "      <td>20.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.134700</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>ci</td>\n",
       "      <td>ci37065303</td>\n",
       "      <td>2014-12-01T18:45:06.920Z</td>\n",
       "      <td>40km ENE of Lucerne Valley, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>34.536167</td>\n",
       "      <td>-116.525833</td>\n",
       "      <td>4.31</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120105</th>\n",
       "      <td>2014-12-01 00:09:25.350</td>\n",
       "      <td>md</td>\n",
       "      <td>8.0</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>0.008991</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc72358451</td>\n",
       "      <td>2014-12-01T01:15:02.814Z</td>\n",
       "      <td>9km WNW of Cobb, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>38.843498</td>\n",
       "      <td>-122.825836</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52122 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          time magType   nst         gap      dmin     rms  \\\n",
       "1      2014-01-31 23:48:35.452      ml   4.0  171.430000  0.342000  0.0247   \n",
       "4      2014-01-31 23:30:52.210      ml   6.0  285.000000  0.043210  0.2000   \n",
       "5      2014-01-31 23:30:36.930      ml  16.0  264.000000  0.080810  0.2100   \n",
       "6      2014-01-31 23:28:04.020      ml  26.0  163.000000  0.032660  0.1200   \n",
       "15     2014-01-31 22:54:06.200      md  13.0  100.799992  0.035933  0.3400   \n",
       "...                        ...     ...   ...         ...       ...     ...   \n",
       "120092 2014-12-01 01:02:27.710      md  13.0  111.000000  0.121400  0.0300   \n",
       "120093 2014-12-01 01:00:29.200      md  26.0  143.000000  0.033850  0.0600   \n",
       "120094 2014-12-01 00:59:41.910      md   7.0  222.000000  0.008552  0.0100   \n",
       "120095 2014-12-01 00:58:43.430      ml  20.0   65.000000  0.134700  0.1600   \n",
       "120105 2014-12-01 00:09:25.350      md   8.0  107.000000  0.008991  0.0300   \n",
       "\n",
       "       net          id                   updated  \\\n",
       "1       nn  nn00436847  2014-02-01T01:35:09.000Z   \n",
       "4       ci  ci37171541  2014-02-01T00:13:20.107Z   \n",
       "5       ci  ci11419722  2014-02-01T00:09:04.470Z   \n",
       "6       ci  ci11419714  2014-02-01T00:54:07.630Z   \n",
       "15      nm   nm020414a  2014-02-04T14:10:26.871Z   \n",
       "...     ..         ...                       ...   \n",
       "120092  nc  nc72358476  2014-12-03T17:30:04.727Z   \n",
       "120093  nc  nc72358466  2014-12-11T06:55:03.683Z   \n",
       "120094  nc  nc72358461  2014-12-01T01:33:06.454Z   \n",
       "120095  ci  ci37065303  2014-12-01T18:45:06.920Z   \n",
       "120105  nc  nc72358451  2014-12-01T01:15:02.814Z   \n",
       "\n",
       "                                         place          type        Lat  \\\n",
       "1                      32km S of Alamo, Nevada    earthquake  37.070300   \n",
       "4                 10km WNW of Progreso, Mexico    earthquake  32.616833   \n",
       "5                     3km N of Tijuana, Mexico  quarry blast  32.567667   \n",
       "6        11km N of Borrego Springs, California    earthquake  33.359000   \n",
       "15               6km SSW of Lilbourn, Missouri    earthquake  36.538300   \n",
       "...                                        ...           ...        ...   \n",
       "120092    25km SE of Mammoth Lakes, California    earthquake  37.473333   \n",
       "120093      11km ESE of Cloverdale, California    earthquake  38.767167   \n",
       "120094       8km NW of The Geysers, California    earthquake  38.830166   \n",
       "120095  40km ENE of Lucerne Valley, California    earthquake  34.536167   \n",
       "120105             9km WNW of Cobb, California    earthquake  38.843498   \n",
       "\n",
       "              Long      D     M  \n",
       "1      -115.130900   0.00  1.33  \n",
       "4      -115.692500  10.59  1.34  \n",
       "5      -117.013500   0.01  1.51  \n",
       "6      -116.360500  12.98  1.17  \n",
       "15      -89.629000   7.80  1.50  \n",
       "...            ...    ...   ...  \n",
       "120092 -118.786333   5.92  0.73  \n",
       "120093 -122.888333   3.56  0.82  \n",
       "120094 -122.833504   1.73  0.29  \n",
       "120095 -116.525833   4.31  1.44  \n",
       "120105 -122.825836   2.37  0.43  \n",
       "\n",
       "[52122 rows x 15 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_df1= eq_df.dropna()\n",
    "\n",
    "eq_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* e. Replace the invalid data with central tendencies. Donâ€™t forget to check if they are categorical or continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time       datetime64[ns]\n",
       "magType            object\n",
       "nst               float64\n",
       "gap               float64\n",
       "dmin              float64\n",
       "rms               float64\n",
       "net                object\n",
       "id                 object\n",
       "updated            object\n",
       "place              object\n",
       "type               object\n",
       "Lat               float64\n",
       "Long              float64\n",
       "D                 float64\n",
       "M                 float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'magType': 'ord',\n",
       " 'type': 'cat',\n",
       " 'net': 'cat',\n",
       " 'gap': 'disc',\n",
       " 'dmin': 'disc',\n",
       " 'time': 'cont',\n",
       " 'updated': 'cont',\n",
       " 'rms': 'cont',\n",
       " 'Lat': 'cont',\n",
       " 'Long': 'cont',\n",
       " 'D': 'cont',\n",
       " 'm': 'cont',\n",
       " 'place': 'nom',\n",
       " 'id': 'nom'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "\"value\" parameter must be a scalar, dict or Series, but you passed a \"ndarray\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-5d2d17a71c1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m#use mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mmode_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meq_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_c_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0meq_df1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_c_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meq_df1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_c_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0meq_df1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_c_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_c_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m \u001b[1;34m'cont'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mfillna\u001b[1;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[0;32m   4515\u001b[0m         \u001b[0mdowncast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4516\u001b[0m     ) -> Optional[\"Series\"]:\n\u001b[1;32m-> 4517\u001b[1;33m         return super().fillna(\n\u001b[0m\u001b[0;32m   4518\u001b[0m             \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4519\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mfillna\u001b[1;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[0;32m   6049\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6050\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6051\u001b[1;33m                     raise TypeError(\n\u001b[0m\u001b[0;32m   6052\u001b[0m                         \u001b[1;34m'\"value\" parameter must be a scalar, dict '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6053\u001b[0m                         \u001b[1;34m\"or Series, but you passed a \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: \"value\" parameter must be a scalar, dict or Series, but you passed a \"ndarray\""
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## General guidelines from Amit\n",
    "# Handling missing values with Central Tendencies \n",
    "    # if data is continious replace NA or NaN by Mean\n",
    "    # if data is discrete replace by Median \n",
    "    # if data is categorical / discrete replace by Mode\n",
    "\n",
    "display(eq_df.dtypes)\n",
    "#### Em's best guesses regarding each column based on earthquake.usgs.gov & Wikipedia.org\n",
    "# found this https://earthquake.usgs.gov/data/comcat/data-eventterms.php\n",
    "# Should we really consider instrument recordings like rms, gap, dmin, as discrete???\n",
    "data_type_dict={\n",
    "    # ordinal categorical\n",
    "    'magType': 'ord',# https://en.wikipedia.org/wiki/Richter_magnitude_scale\n",
    "    # categorical\n",
    "    'type': 'cat', # Type of seismic event.\n",
    "    'net': 'cat', # The ID of a data contributor. Identifies the network considered to be the preferred source of information for this event.\n",
    "    # discreet\n",
    "    'gap': 'disc', # The largest azimuthal gap between azimuthally adjacent stations (in degrees).\n",
    "    'dmin': 'disc', # Horizontal distance from the epicenter to the nearest station (in degrees). 1 degree is approximately 111.2 kilometers.\n",
    "    # continuous\n",
    "    'time': 'cont', # time quake observed\n",
    "    'updated': 'cont', # time record was updated\n",
    "    'rms': 'cont', # \"root mean square\" travel time 2194 unique values for dataset of 52122 ... maybe it should be treated as categorical? # https://earthquake.usgs.gov/data/comcat/data-eventterms.php#:~:text=The%20root%2Dmean%2Dsquare%20(,arrival%20times%20for%20this%20location.\n",
    "    'Lat': 'cont', # Latitude\n",
    "    'Long': 'cont', # Longitude\n",
    "    'D': 'cont', # Depth of the event in kilometers.\n",
    "    'm': 'cont', # richter magnitude # The Richter magnitude of an earthquake is determined from the logarithm of the amplitude of waves recorded by seismographs\n",
    "    # nominal\n",
    "    'place': 'nom', #Textual description of named geographic region near to the event. \n",
    "    'id': 'nom', # A unique identifier for the event.\n",
    "    }\n",
    "display(data_type_dict)\n",
    "['time', 'magType', 'nst', 'gap', 'dmin', 'rms', 'net', 'id', 'updated',\n",
    "       'place', 'type', 'Lat', 'Long', 'D', 'M']\n",
    "###############\n",
    "#_c = 'M' \n",
    "#display(f\"{len(eq_df[f'{_c}'].unique())} unique values in {_c}\",\n",
    "#        sorted(eq_df[f'{_c}'].unique()),\n",
    "#        eq_df[f'{_c}'].unique(),       \n",
    "#        f\"col:{_c}\\nmax:{np.max(eq_df[_c])}\\nmin:{np.min(eq_df[_c])}\"\n",
    "#        )\n",
    "\n",
    "for _c_t in data_type_dict.items():\n",
    "    if _c_t[1] in ['ord', 'cat']:\n",
    "        #use mode\n",
    "        mode_result = mode(eq_df[_c_t[0]])\n",
    "        eq_df1[_c_t[0]] = eq_df1[_c_t[0]].fillna(mode_result.mode)\n",
    "        eq_df1[_c_t[0]].fillna(mode_result.mode, inplace=True)        \n",
    "    if _c_t[1]== 'cont':\n",
    "        #use mean\n",
    "        eq_df1[_c_t[0]] = eq_df1[_c_t[0]].fillna(np.mean(eq_df1[_c_t[0]]))\n",
    "    if _c_t[1]== 'disc':\n",
    "        #use median\n",
    "        eq_df1[_c_t[0]] = eq_df1[_c_t[0]].fillna(np.median(eq_df1[_c_t[0]]))\n",
    "         \n",
    "#diabetes_df1['Insulin'] = diabetes_df1['Insulin'].fillna(np.mean(diabetes_df1['Insulin']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(eq_df1.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* f. Compute the mean and standard deviation of each of D, M in earthquake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_variance(array):\n",
    "    def mean(a):\n",
    "        return(np.sum(a)/len(a))\n",
    "    _m = mean(array)\n",
    "    n_a = [(i - _m)**2 for i in array]\n",
    "    _v = mean(n_a)\n",
    "    return(_v)\n",
    "def naive_stdv(a):\n",
    "    return(np.sqrt(naive_variance(a)))\n",
    "\n",
    "\n",
    "display(f\"mean of D : {np.mean(eq_df1['D'])}\\nSTDV of D : {naive_stdv(eq_df1['D'])}\")\n",
    "display(f\"mean of M : {np.mean(eq_df1['M'])}\\nSTDV of M : {naive_stdv(eq_df1['M'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8)Convert the date into day of month, week number, day of year and day of week from a series of date strings?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09 00:00:00 9 50 344 Wednesday\n",
      "2020-12-31 00:00:00 31 53 366 Thursday\n",
      "2021-07-21 00:00:00 21 29 202 Wednesday\n",
      "2021-10-31 00:00:00 31 43 304 Sunday\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__closure__',\n",
       " '__code__',\n",
       " '__defaults__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get__',\n",
       " '__getattribute__',\n",
       " '__globals__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__kwdefaults__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__qualname__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "dt_s = pd.Series([\"12-09-2020\", \"12-31-2020\", \"07-21-2021\", \"10-31-2021\"])\n",
    "dt_s = pd.to_datetime(dt_s)\n",
    "\n",
    "[print(dt, dt.day, dt.week, dt.dayofyear,  dt.day_name(), end=\"\\n\") for dt in dt_s]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysing data using url:\n",
    "     https://raw.githubusercontent.com/ammishra08/MachineLearning/master/Datasets/house_sales_data.csv\n",
    "* a. Load the data file\n",
    "\n",
    "\n",
    "\n",
    "* e. Filter the columns with Price > 250000 and view is True.\n",
    "* f. Compute the average price of house with sqft_living > 25000 and view is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_df = pd.read_csv('https://raw.githubusercontent.com/ammishra08/MachineLearning/master/Datasets/house_sales_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1149</td>\n",
       "      <td>3421079032</td>\n",
       "      <td>20150217T000000</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>670</td>\n",
       "      <td>43377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>670</td>\n",
       "      <td>0</td>\n",
       "      <td>1966</td>\n",
       "      <td>0</td>\n",
       "      <td>98022</td>\n",
       "      <td>47.2638</td>\n",
       "      <td>-121.906</td>\n",
       "      <td>1160</td>\n",
       "      <td>42882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15293</td>\n",
       "      <td>40000362</td>\n",
       "      <td>20140506T000000</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>780</td>\n",
       "      <td>16344</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>780</td>\n",
       "      <td>0</td>\n",
       "      <td>1942</td>\n",
       "      <td>0</td>\n",
       "      <td>98168</td>\n",
       "      <td>47.4739</td>\n",
       "      <td>-122.280</td>\n",
       "      <td>1700</td>\n",
       "      <td>10387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>465</td>\n",
       "      <td>8658300340</td>\n",
       "      <td>20140523T000000</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>430</td>\n",
       "      <td>5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>430</td>\n",
       "      <td>0</td>\n",
       "      <td>1912</td>\n",
       "      <td>0</td>\n",
       "      <td>98014</td>\n",
       "      <td>47.6499</td>\n",
       "      <td>-121.909</td>\n",
       "      <td>1200</td>\n",
       "      <td>7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>16198</td>\n",
       "      <td>3028200080</td>\n",
       "      <td>20150324T000000</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>730</td>\n",
       "      <td>9975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>730</td>\n",
       "      <td>0</td>\n",
       "      <td>1943</td>\n",
       "      <td>0</td>\n",
       "      <td>98168</td>\n",
       "      <td>47.4808</td>\n",
       "      <td>-122.315</td>\n",
       "      <td>860</td>\n",
       "      <td>9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8274</td>\n",
       "      <td>3883800011</td>\n",
       "      <td>20141105T000000</td>\n",
       "      <td>82000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>860</td>\n",
       "      <td>10426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>1954</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.4987</td>\n",
       "      <td>-122.341</td>\n",
       "      <td>1140</td>\n",
       "      <td>11250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>21608</td>\n",
       "      <td>1448</td>\n",
       "      <td>8907500070</td>\n",
       "      <td>20150413T000000</td>\n",
       "      <td>5350000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.00</td>\n",
       "      <td>8000</td>\n",
       "      <td>23985</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>6720</td>\n",
       "      <td>1280</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98004</td>\n",
       "      <td>47.6232</td>\n",
       "      <td>-122.220</td>\n",
       "      <td>4600</td>\n",
       "      <td>21750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>21609</td>\n",
       "      <td>4411</td>\n",
       "      <td>2470100110</td>\n",
       "      <td>20140804T000000</td>\n",
       "      <td>5570000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.75</td>\n",
       "      <td>9200</td>\n",
       "      <td>35069</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>6200</td>\n",
       "      <td>3000</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>98039</td>\n",
       "      <td>47.6289</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>3560</td>\n",
       "      <td>24345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>21610</td>\n",
       "      <td>9254</td>\n",
       "      <td>9208900037</td>\n",
       "      <td>20140919T000000</td>\n",
       "      <td>6885000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7.75</td>\n",
       "      <td>9890</td>\n",
       "      <td>31374</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>8860</td>\n",
       "      <td>1030</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>98039</td>\n",
       "      <td>47.6305</td>\n",
       "      <td>-122.240</td>\n",
       "      <td>4540</td>\n",
       "      <td>42730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>21611</td>\n",
       "      <td>3914</td>\n",
       "      <td>9808700762</td>\n",
       "      <td>20140611T000000</td>\n",
       "      <td>7062500.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.50</td>\n",
       "      <td>10040</td>\n",
       "      <td>37325</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>7680</td>\n",
       "      <td>2360</td>\n",
       "      <td>1940</td>\n",
       "      <td>2001</td>\n",
       "      <td>98004</td>\n",
       "      <td>47.6500</td>\n",
       "      <td>-122.214</td>\n",
       "      <td>3930</td>\n",
       "      <td>25449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>21612</td>\n",
       "      <td>7252</td>\n",
       "      <td>6762700020</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>7700000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>8.00</td>\n",
       "      <td>12050</td>\n",
       "      <td>27600</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>8570</td>\n",
       "      <td>3480</td>\n",
       "      <td>1910</td>\n",
       "      <td>1987</td>\n",
       "      <td>98102</td>\n",
       "      <td>47.6298</td>\n",
       "      <td>-122.323</td>\n",
       "      <td>3940</td>\n",
       "      <td>8800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       level_0  index          id             date      price  bedrooms  \\\n",
       "0            0   1149  3421079032  20150217T000000    75000.0         1   \n",
       "1            1  15293    40000362  20140506T000000    78000.0         2   \n",
       "2            2    465  8658300340  20140523T000000    80000.0         1   \n",
       "3            3  16198  3028200080  20150324T000000    81000.0         2   \n",
       "4            4   8274  3883800011  20141105T000000    82000.0         3   \n",
       "...        ...    ...         ...              ...        ...       ...   \n",
       "21608    21608   1448  8907500070  20150413T000000  5350000.0         5   \n",
       "21609    21609   4411  2470100110  20140804T000000  5570000.0         5   \n",
       "21610    21610   9254  9208900037  20140919T000000  6885000.0         6   \n",
       "21611    21611   3914  9808700762  20140611T000000  7062500.0         5   \n",
       "21612    21612   7252  6762700020  20141013T000000  7700000.0         6   \n",
       "\n",
       "       bathrooms  sqft_living  sqft_lot  floors  ...  grade  sqft_above  \\\n",
       "0           0.00          670     43377     1.0  ...      3         670   \n",
       "1           1.00          780     16344     1.0  ...      5         780   \n",
       "2           0.75          430      5050     1.0  ...      4         430   \n",
       "3           1.00          730      9975     1.0  ...      5         730   \n",
       "4           1.00          860     10426     1.0  ...      6         860   \n",
       "...          ...          ...       ...     ...  ...    ...         ...   \n",
       "21608       5.00         8000     23985     2.0  ...     12        6720   \n",
       "21609       5.75         9200     35069     2.0  ...     13        6200   \n",
       "21610       7.75         9890     31374     2.0  ...     13        8860   \n",
       "21611       4.50        10040     37325     2.0  ...     11        7680   \n",
       "21612       8.00        12050     27600     2.5  ...     13        8570   \n",
       "\n",
       "       sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0                  0      1966             0    98022  47.2638 -121.906   \n",
       "1                  0      1942             0    98168  47.4739 -122.280   \n",
       "2                  0      1912             0    98014  47.6499 -121.909   \n",
       "3                  0      1943             0    98168  47.4808 -122.315   \n",
       "4                  0      1954             0    98146  47.4987 -122.341   \n",
       "...              ...       ...           ...      ...      ...      ...   \n",
       "21608           1280      2009             0    98004  47.6232 -122.220   \n",
       "21609           3000      2001             0    98039  47.6289 -122.233   \n",
       "21610           1030      2001             0    98039  47.6305 -122.240   \n",
       "21611           2360      1940          2001    98004  47.6500 -122.214   \n",
       "21612           3480      1910          1987    98102  47.6298 -122.323   \n",
       "\n",
       "       sqft_living15  sqft_lot15  \n",
       "0               1160       42882  \n",
       "1               1700       10387  \n",
       "2               1200        7500  \n",
       "3                860        9000  \n",
       "4               1140       11250  \n",
       "...              ...         ...  \n",
       "21608           4600       21750  \n",
       "21609           3560       24345  \n",
       "21610           4540       42730  \n",
       "21611           3930       25449  \n",
       "21612           3940        8800  \n",
       "\n",
       "[21613 rows x 23 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b. Sorting the Rows Data using Column â€˜priceâ€™ and reset the updated dataframe.\n",
    "hs_df.sort_values('price', inplace=True)\n",
    "hs_df.reset_index(inplace=True)\n",
    "hs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'level_0'),\n",
       " (1, 'index'),\n",
       " (2, 'id'),\n",
       " (3, 'date'),\n",
       " (4, 'price'),\n",
       " (5, 'bedrooms'),\n",
       " (6, 'bathrooms'),\n",
       " (7, 'sqft_living'),\n",
       " (8, 'sqft_lot'),\n",
       " (9, 'floors'),\n",
       " (10, 'waterfront'),\n",
       " (11, 'view'),\n",
       " (12, 'condition'),\n",
       " (13, 'grade'),\n",
       " (14, 'sqft_above'),\n",
       " (15, 'sqft_basement'),\n",
       " (16, 'yr_built'),\n",
       " (17, 'yr_renovated'),\n",
       " (18, 'zipcode'),\n",
       " (19, 'lat'),\n",
       " (20, 'long'),\n",
       " (21, 'sqft_living15'),\n",
       " (22, 'sqft_lot15')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2500600289</td>\n",
       "      <td>20150416T000000</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>790</td>\n",
       "      <td>7500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>13001215</td>\n",
       "      <td>20150305T000000</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1100</td>\n",
       "      <td>5100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>41000454</td>\n",
       "      <td>20140815T000000</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>880</td>\n",
       "      <td>9000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>4014400237</td>\n",
       "      <td>20140523T000000</td>\n",
       "      <td>132500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1080</td>\n",
       "      <td>10500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6303401050</td>\n",
       "      <td>20150220T000000</td>\n",
       "      <td>132500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>850</td>\n",
       "      <td>8573</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>6147600040</td>\n",
       "      <td>20150224T000000</td>\n",
       "      <td>163000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1290</td>\n",
       "      <td>4811</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1443501020</td>\n",
       "      <td>20141113T000000</td>\n",
       "      <td>163250.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>8150</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>7468900235</td>\n",
       "      <td>20141022T000000</td>\n",
       "      <td>163500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>940</td>\n",
       "      <td>7200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>6661200320</td>\n",
       "      <td>20140723T000000</td>\n",
       "      <td>163500.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1050</td>\n",
       "      <td>3419</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>2724049222</td>\n",
       "      <td>20140802T000000</td>\n",
       "      <td>163800.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1092</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "100  2500600289  20150416T000000  130000.0         2       1.00          790   \n",
       "101    13001215  20150305T000000  130000.0         3       1.00         1100   \n",
       "102    41000454  20140815T000000  130000.0         2       1.00          880   \n",
       "103  4014400237  20140523T000000  132500.0         3       1.00         1080   \n",
       "104  6303401050  20150220T000000  132500.0         3       0.75          850   \n",
       "..          ...              ...       ...       ...        ...          ...   \n",
       "296  6147600040  20150224T000000  163000.0         3       1.75         1290   \n",
       "297  1443501020  20141113T000000  163250.0         2       1.00          770   \n",
       "298  7468900235  20141022T000000  163500.0         3       1.00          940   \n",
       "299  6661200320  20140723T000000  163500.0         2       1.50         1050   \n",
       "300  2724049222  20140802T000000  163800.0         2       2.50         1000   \n",
       "\n",
       "     sqft_lot  floors  \n",
       "100      7500     1.0  \n",
       "101      5100     1.0  \n",
       "102      9000     1.0  \n",
       "103     10500     1.0  \n",
       "104      8573     1.0  \n",
       "..        ...     ...  \n",
       "296      4811     1.0  \n",
       "297      8150     1.0  \n",
       "298      7200     1.0  \n",
       "299      3419     2.0  \n",
       "300      1092     2.0  \n",
       "\n",
       "[201 rows x 8 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c. Slice the rows and columns using iloc row positions 100 to 300 , columns 2 to 9 positions.\n",
    "hs_df.iloc[100:301, 2:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1149</td>\n",
       "      <td>3421079032</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>670</td>\n",
       "      <td>43377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1966</td>\n",
       "      <td>98022</td>\n",
       "      <td>-121.906</td>\n",
       "      <td>1160</td>\n",
       "      <td>42882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15293</td>\n",
       "      <td>40000362</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>780</td>\n",
       "      <td>16344</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1942</td>\n",
       "      <td>98168</td>\n",
       "      <td>-122.280</td>\n",
       "      <td>1700</td>\n",
       "      <td>10387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>465</td>\n",
       "      <td>8658300340</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1912</td>\n",
       "      <td>98014</td>\n",
       "      <td>-121.909</td>\n",
       "      <td>1200</td>\n",
       "      <td>7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>16198</td>\n",
       "      <td>3028200080</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>730</td>\n",
       "      <td>9975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1943</td>\n",
       "      <td>98168</td>\n",
       "      <td>-122.315</td>\n",
       "      <td>860</td>\n",
       "      <td>9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8274</td>\n",
       "      <td>3883800011</td>\n",
       "      <td>82000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>860</td>\n",
       "      <td>10426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1954</td>\n",
       "      <td>98146</td>\n",
       "      <td>-122.341</td>\n",
       "      <td>1140</td>\n",
       "      <td>11250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>21608</td>\n",
       "      <td>1448</td>\n",
       "      <td>8907500070</td>\n",
       "      <td>5350000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>8000</td>\n",
       "      <td>23985</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2009</td>\n",
       "      <td>98004</td>\n",
       "      <td>-122.220</td>\n",
       "      <td>4600</td>\n",
       "      <td>21750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>21609</td>\n",
       "      <td>4411</td>\n",
       "      <td>2470100110</td>\n",
       "      <td>5570000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>9200</td>\n",
       "      <td>35069</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2001</td>\n",
       "      <td>98039</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>3560</td>\n",
       "      <td>24345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>21610</td>\n",
       "      <td>9254</td>\n",
       "      <td>9208900037</td>\n",
       "      <td>6885000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>9890</td>\n",
       "      <td>31374</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2001</td>\n",
       "      <td>98039</td>\n",
       "      <td>-122.240</td>\n",
       "      <td>4540</td>\n",
       "      <td>42730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>21611</td>\n",
       "      <td>3914</td>\n",
       "      <td>9808700762</td>\n",
       "      <td>7062500.0</td>\n",
       "      <td>5</td>\n",
       "      <td>10040</td>\n",
       "      <td>37325</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1940</td>\n",
       "      <td>98004</td>\n",
       "      <td>-122.214</td>\n",
       "      <td>3930</td>\n",
       "      <td>25449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>21612</td>\n",
       "      <td>7252</td>\n",
       "      <td>6762700020</td>\n",
       "      <td>7700000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>12050</td>\n",
       "      <td>27600</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1910</td>\n",
       "      <td>98102</td>\n",
       "      <td>-122.323</td>\n",
       "      <td>3940</td>\n",
       "      <td>8800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       level_0  index          id      price  bedrooms  sqft_living  sqft_lot  \\\n",
       "0            0   1149  3421079032    75000.0         1          670     43377   \n",
       "1            1  15293    40000362    78000.0         2          780     16344   \n",
       "2            2    465  8658300340    80000.0         1          430      5050   \n",
       "3            3  16198  3028200080    81000.0         2          730      9975   \n",
       "4            4   8274  3883800011    82000.0         3          860     10426   \n",
       "...        ...    ...         ...        ...       ...          ...       ...   \n",
       "21608    21608   1448  8907500070  5350000.0         5         8000     23985   \n",
       "21609    21609   4411  2470100110  5570000.0         5         9200     35069   \n",
       "21610    21610   9254  9208900037  6885000.0         6         9890     31374   \n",
       "21611    21611   3914  9808700762  7062500.0         5        10040     37325   \n",
       "21612    21612   7252  6762700020  7700000.0         6        12050     27600   \n",
       "\n",
       "       floors  view  condition  yr_built  zipcode     long  sqft_living15  \\\n",
       "0         1.0     0          3      1966    98022 -121.906           1160   \n",
       "1         1.0     0          1      1942    98168 -122.280           1700   \n",
       "2         1.0     0          2      1912    98014 -121.909           1200   \n",
       "3         1.0     0          1      1943    98168 -122.315            860   \n",
       "4         1.0     0          3      1954    98146 -122.341           1140   \n",
       "...       ...   ...        ...       ...      ...      ...            ...   \n",
       "21608     2.0     4          3      2009    98004 -122.220           4600   \n",
       "21609     2.0     0          3      2001    98039 -122.233           3560   \n",
       "21610     2.0     4          3      2001    98039 -122.240           4540   \n",
       "21611     2.0     2          3      1940    98004 -122.214           3930   \n",
       "21612     2.5     3          4      1910    98102 -122.323           3940   \n",
       "\n",
       "       sqft_lot15  \n",
       "0           42882  \n",
       "1           10387  \n",
       "2            7500  \n",
       "3            9000  \n",
       "4           11250  \n",
       "...           ...  \n",
       "21608       21750  \n",
       "21609       24345  \n",
       "21610       42730  \n",
       "21611       25449  \n",
       "21612        8800  \n",
       "\n",
       "[21613 rows x 15 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#* d. Filter all columns with letter â€˜aâ€™ in it\n",
    "cols_a = [s for s in hs_df.columns if 'a' in s]\n",
    "hs_df[[c for c in hs_df.columns if c not in cols_a]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10) Create a string series data with spaces. Replace the missing spaces in a string with least frequent value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Hellowelcomeandwelcomewelcome\n",
       "1                            hello\n",
       "2                            hello\n",
       "3                          welcome\n",
       "4                              yes\n",
       "5                              yes\n",
       "6    Hellowelcomeandwelcomewelcome\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = pd.Series([\"Hello and welcome\", 'hello', 'hello', 'welcome', 'yes', 'yes', \"Hello and welcome\"])\n",
    "r = r\"[ ]\"\n",
    "\n",
    "x.replace(r, x.value_counts().index[-1], regex=True, inplace=True)\n",
    "\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
