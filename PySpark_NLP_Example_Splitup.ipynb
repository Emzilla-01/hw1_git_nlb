{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "common-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, StopWordsRemover, NGram, HashingTF, IDF, CountVectorizer, OneHotEncoder, StringIndexer, Word2Vec\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "#from pyspark.mllib.classification import NaiveBayes#, NaiveBayesModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suited-chick",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------+-----+\n",
      "|Title                                                                             |count|\n",
      "+----------------------------------------------------------------------------------+-----+\n",
      "|The article requested cannot be found! Please refresh your browser or go back  ...|145  |\n",
      "|Business Highlights                                                               |59   |\n",
      "|Posted by Parvez Jabri                                                            |59   |\n",
      "|Posted by Imaduddin                                                               |53   |\n",
      "|Posted by Shoaib-ur-Rehman Siddiqui                                               |52   |\n",
      "|(click the phrases to see a list)                                                 |51   |\n",
      "|Business Wire                                                                     |41   |\n",
      "|PR Newswire                                                                       |38   |\n",
      "|Posted by Muhammad Iqbal                                                          |35   |\n",
      "|Change text size for the story                                                    |34   |\n",
      "|Get the Most Popular Beauty World News Stories in a Weekly Newsletter             |34   |\n",
      "|International markets roundup                                                     |33   |\n",
      "|Business briefs                                                                   |33   |\n",
      "|India Morning Call-Global Markets                                                 |27   |\n",
      "|10 Things to Know for Today                                                       |22   |\n",
      "|Breaking news                                                                     |21   |\n",
      "|Perez Recommends                                                                  |19   |\n",
      "|From ColumbusAlive.com                                                            |18   |\n",
      "|Texas Weekly Gas Price Update and Outlook                                         |18   |\n",
      "|The Daily Dish                                                                    |17   |\n",
      "+----------------------------------------------------------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+--------------------+\n",
      "|               words|      filtered_words|\n",
      "+--------------------+--------------------+\n",
      "|[fed, official, s...|[fed, official, s...|\n",
      "|[fed, s, charles,...|[fed, charles, pl...|\n",
      "|[us, open, stocks...|[us, open, stocks...|\n",
      "|[fed, risks, fall...|[fed, risks, fall...|\n",
      "|[fed, s, plosser,...|[fed, plosser, na...|\n",
      "|[plosser, fed, ma...|[plosser, fed, ma...|\n",
      "|[fed, s, plosser,...|[fed, plosser, ta...|\n",
      "|[fed, s, plosser,...|[fed, plosser, ex...|\n",
      "|[us, jobs, growth...|[us, jobs, growth...|\n",
      "|[ecb, unlikely, t...|[ecb, unlikely, e...|\n",
      "|[ecb, unlikely, t...|[ecb, unlikely, e...|\n",
      "|[eu, s, half, bak...|[eu, half, baked,...|\n",
      "|[europe, reaches,...|[europe, reaches,...|\n",
      "|[ecb, focus, stro...|[ecb, focus, stro...|\n",
      "|[eu, aims, for, d...|[eu, aims, deal, ...|\n",
      "|[forex, pound, dr...|[forex, pound, dr...|\n",
      "|[noyer, says, str...|[noyer, says, str...|\n",
      "|[eu, week, ahead,...|[eu, week, ahead,...|\n",
      "|[ecb, member, noy...|[ecb, member, noy...|\n",
      "|[euro, anxieties,...|[euro, anxieties,...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "news_data = spark.read.csv('file:///home/hadoop/data/Case_News_Articles.csv', header=True, inferSchema=True)\n",
    "\n",
    "#news_data.show()\n",
    "\n",
    "title_category = news_data.select(\"TITLE\", \"CATEGORY\")\n",
    "\n",
    "#title_category.show()\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "#title_category.select([count(when(isnull(c), c)).alias(c) for c in title_category.columns]).show()\n",
    "\n",
    "title_category = title_category.dropna()\n",
    "\n",
    "#title_category.count()\n",
    "\n",
    "#title_category.show(truncate=False)\n",
    "\n",
    "title_category.groupby('Title').count().orderBy(col(\"count\").desc()).show(truncate = False)\n",
    "\n",
    "# regexp_replace(col('TITLE'), '\\d+', '') - Remove all the numbers with blank \n",
    "title_category = title_category.withColumn(\"title_str\", regexp_replace(col('TITLE'), '\\d+', ''))\n",
    "\n",
    "#title_category.select(\"TITLE\", \"title_str\").show(truncate= False)\n",
    "\n",
    "regex_tokenizer = RegexTokenizer(inputCol=\"title_str\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "raw_words = regex_tokenizer.transform(title_category)\n",
    "\n",
    "#raw_words.show()\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "\n",
    "words_df = remover.transform(raw_words)\n",
    "\n",
    "words_df.select(\"words\", \"filtered_words\").show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "agreed-beaver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------+-------------------------------------------------------------------------------+\n",
      "|words                                                                                |filtered_words                                                                 |\n",
      "+-------------------------------------------------------------------------------------+-------------------------------------------------------------------------------+\n",
      "|[fed, official, says, weak, data, caused, by, weather, should, not, slow, taper]     |[fed, official, says, weak, data, caused, weather, slow, taper]                |\n",
      "|[fed, s, charles, plosser, sees, high, bar, for, change, in, pace, of, tapering]     |[fed, charles, plosser, sees, high, bar, change, pace, tapering]               |\n",
      "|[us, open, stocks, fall, after, fed, official, hints, at, accelerated, tapering]     |[us, open, stocks, fall, fed, official, hints, accelerated, tapering]          |\n",
      "|[fed, risks, falling, behind, the, curve, charles, plosser, says]                    |[fed, risks, falling, behind, curve, charles, plosser, says]                   |\n",
      "|[fed, s, plosser, nasty, weather, has, curbed, job, growth]                          |[fed, plosser, nasty, weather, curbed, job, growth]                            |\n",
      "|[plosser, fed, may, have, to, accelerate, tapering, pace]                            |[plosser, fed, may, accelerate, tapering, pace]                                |\n",
      "|[fed, s, plosser, taper, pace, may, be, too, slow]                                   |[fed, plosser, taper, pace, may, slow]                                         |\n",
      "|[fed, s, plosser, expects, us, unemployment, to, fall, to, by, the, end, of]         |[fed, plosser, expects, us, unemployment, fall, end]                           |\n",
      "|[us, jobs, growth, last, month, hit, by, weather, fed, president, charles, plosser]  |[us, jobs, growth, last, month, hit, weather, fed, president, charles, plosser]|\n",
      "|[ecb, unlikely, to, end, sterilisation, of, smp, purchases, traders]                 |[ecb, unlikely, end, sterilisation, smp, purchases, traders]                   |\n",
      "|[ecb, unlikely, to, end, sterilization, of, smp, purchases, traders]                 |[ecb, unlikely, end, sterilization, smp, purchases, traders]                   |\n",
      "|[eu, s, half, baked, bank, union, could, work]                                       |[eu, half, baked, bank, union, work]                                           |\n",
      "|[europe, reaches, crunch, point, on, banking, union]                                 |[europe, reaches, crunch, point, banking, union]                               |\n",
      "|[ecb, focus, stronger, euro, drowns, out, ecb, s, message, to, keep, rates, low, for]|[ecb, focus, stronger, euro, drowns, ecb, message, keep, rates, low]           |\n",
      "|[eu, aims, for, deal, on, tackling, failing, banks]                                  |[eu, aims, deal, tackling, failing, banks]                                     |\n",
      "|[forex, pound, drops, to, one, month, lows, against, euro]                           |[forex, pound, drops, one, month, lows, euro]                                  |\n",
      "|[noyer, says, strong, euro, creates, unwarranted, economic, pressure]                |[noyer, says, strong, euro, creates, unwarranted, economic, pressure]          |\n",
      "|[eu, week, ahead, march, bank, resolution, transparency, ukraine]                    |[eu, week, ahead, march, bank, resolution, transparency, ukraine]              |\n",
      "|[ecb, member, noyer, is, very, open, to, all, kinds, of, tools]                      |[ecb, member, noyer, open, kinds, tools]                                       |\n",
      "|[euro, anxieties, wane, as, bunds, top, treasuries, spain, debt, rallies]            |[euro, anxieties, wane, bunds, top, treasuries, spain, debt, rallies]          |\n",
      "+-------------------------------------------------------------------------------------+-------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_df.select(\"words\", \"filtered_words\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bridal-perception",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TITLE: string (nullable = true)\n",
      " |-- CATEGORY: string (nullable = true)\n",
      " |-- title_str: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- filtered_words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-closure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "architectural-gabriel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+--------------------+--------------------+\n",
      "|               TITLE|CATEGORY|           title_str|               words|      filtered_words|            features|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Fed official says...|       b|Fed official says...|[fed, official, s...|[fed, official, s...|(49043,[5,42,112,...|\n",
      "|Fed's Charles Plo...|       b|Fed's Charles Plo...|[fed, s, charles,...|[fed, charles, pl...|(49043,[58,84,112...|\n",
      "|US open: Stocks f...|       b|US open: Stocks f...|[us, open, stocks...|[us, open, stocks...|(49043,[1,27,112,...|\n",
      "|Fed risks falling...|       b|Fed risks falling...|[fed, risks, fall...|[fed, risks, fall...|(49043,[5,112,578...|\n",
      "|Fed's Plosser: Na...|       b|Fed's Plosser: Na...|[fed, s, plosser,...|[fed, plosser, na...|(49043,[112,121,5...|\n",
      "|Plosser: Fed May ...|       b|Plosser: Fed May ...|[plosser, fed, ma...|[plosser, fed, ma...|(49043,[8,112,223...|\n",
      "|Fed's Plosser: Ta...|       b|Fed's Plosser: Ta...|[fed, s, plosser,...|[fed, plosser, ta...|(49043,[8,112,123...|\n",
      "|Fed's Plosser exp...|       b|Fed's Plosser exp...|[fed, s, plosser,...|[fed, plosser, ex...|(49043,[1,112,135...|\n",
      "|US jobs growth la...|       b|US jobs growth la...|[us, jobs, growth...|[us, jobs, growth...|(49043,[1,112,121...|\n",
      "|ECB unlikely to e...|       b|ECB unlikely to e...|[ecb, unlikely, t...|[ecb, unlikely, e...|(49043,[135,200,2...|\n",
      "|ECB unlikely to e...|       b|ECB unlikely to e...|[ecb, unlikely, t...|[ecb, unlikely, e...|(49043,[135,200,2...|\n",
      "|EU's half-baked b...|       b|EU's half-baked b...|[eu, s, half, bak...|[eu, half, baked,...|(49043,[78,535,60...|\n",
      "|Europe reaches cr...|       b|Europe reaches cr...|[europe, reaches,...|[europe, reaches,...|(49043,[405,939,1...|\n",
      "|ECB FOCUS-Stronge...|       b|ECB FOCUS-Stronge...|[ecb, focus, stro...|[ecb, focus, stro...|(49043,[133,171,1...|\n",
      "|EU aims for deal ...|       b|EU aims for deal ...|[eu, aims, for, d...|[eu, aims, deal, ...|(49043,[29,593,64...|\n",
      "|Forex - Pound dro...|       b|Forex - Pound dro...|[forex, pound, dr...|[forex, pound, dr...|(49043,[10,171,17...|\n",
      "|Noyer Says Strong...|       b|Noyer Says Strong...|[noyer, says, str...|[noyer, says, str...|(49043,[5,171,438...|\n",
      "|EU Week Ahead Mar...|       b|EU Week Ahead Mar...|[eu, week, ahead,...|[eu, week, ahead,...|(49043,[56,78,168...|\n",
      "|ECB member Noyer ...|       b|ECB member Noyer ...|[ecb, member, noy...|[ecb, member, noy...|(49043,[200,240,3...|\n",
      "|Euro Anxieties Wa...|       b|Euro Anxieties Wa...|[euro, anxieties,...|[euro, anxieties,...|(49043,[47,171,10...|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(inputCol=\"filtered_words\", outputCol=\"features\")\n",
    "model = cv.fit(words_df)\n",
    "features_data = model.transform(words_df)\n",
    "\n",
    "features_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "reliable-oklahoma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TITLE: string (nullable = true)\n",
      " |-- CATEGORY: string (nullable = true)\n",
      " |-- title_str: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- filtered_words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- categoryIndex: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol=\"CATEGORY\", outputCol=\"categoryIndex\").fit(features_data)\n",
    "#feature_data = indexer.fit(features_data).transform(features_data)\n",
    "features_data = indexer.transform(features_data)\n",
    "\n",
    "#features_data.select(\"CATEGORY\", \"categoryIndex\").show()\n",
    "\n",
    "features_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "precise-battery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TITLE: string (nullable = true)\n",
      " |-- CATEGORY: string (nullable = true)\n",
      " |-- title_str: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- filtered_words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#features_data.select(\"CATEGORY\", \"categoryIndex\").show()\n",
    "\n",
    "features_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-lightweight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+\n",
      "|prediction|categoryIndex|            features|\n",
      "+----------+-------------+--------------------+\n",
      "|       0.0|          0.0|(49043,[167,553,9...|\n",
      "|       0.0|        161.0|(49043,[268,373,5...|\n",
      "|       0.0|          0.0|(49043,[20,33,51,...|\n",
      "|       0.0|          0.0|(49043,[59,950,23...|\n",
      "|       0.0|         20.0|(49043,[153,325,5...|\n",
      "+----------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_Data, test_Data = features_data.randomSplit([0.8, 0.2], seed = 11)\n",
    "\n",
    "# One Hot Encoding - Sklearn , Neural Network\n",
    "# Sparse matrix - most of entries are zeros\n",
    "# [0] - [1, 0, 0, 0, 0, 0]\n",
    "# [1] - [0, 1, 0, 0, 0, 0]\n",
    "# [2] - [0, 0, 1, 0, 0, 0]\n",
    "# [3] - [0, 0, 0, 1, 0, 0]\n",
    "# [4] - [0, 0, 0, 0, 1, 0]\n",
    "# [5] - [0, 0, 0, 0, 0, 1]\n",
    "\n",
    "# \n",
    "#a - [1, 0, 0, 0]\n",
    "#b - [0, 1, 0, 0]\n",
    "#c - [0, 0, 1, 0]\n",
    "#d - [0, 0, 0, 1]\n",
    "\n",
    "NB = NaiveBayes(modelType= \"multinomial\", labelCol=\"categoryIndex\", featuresCol=\"features\" )\n",
    "nbModel = NB.fit(train_Data)\n",
    "\n",
    "nb_predictions = nbModel.transform(test_Data)\n",
    "\n",
    "nb_predictions.select(\"prediction\", \"categoryIndex\", \"features\").show(5)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol= \"categoryIndex\", predictionCol = \"prediction\", \n",
    "                                              metricName=\"accuracy\")\n",
    "\n",
    "nb_accuracy = evaluator.evaluate(nb_predictions)\n",
    "\n",
    "print(\"Accuracy : \", nb_accuracy)\n",
    "\n",
    "nb_predictions.groupby('prediction').count().orderBy(col(\"count\").desc()).show(truncate = False)\n",
    "\n",
    "test_Data.groupby('Category').count().orderBy(col(\"count\").desc()).show(truncate = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-orchestra",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
