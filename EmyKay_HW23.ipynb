{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "## Assignment 23\n",
    "\n",
    "### UBER AND LYFT\n",
    "Uber and Lyft's ride prices are not constant like public transport. They are greatly affected by the demand and supply of rides at a given time. So what exactly drives this demand? The first guess would be the time of the day times around 9 am and 5 pm should see the highest surges on account of people commuting to work/home. Another guess would be the weather; rain/snow should cause more people to take rides. \n",
    "\n",
    "As a data analyst you should rely on exploring hidden insights of data and not on making guesses. The following dataset is for Uber and Lyft rides and Weather condition. Battle both cab booking data and find the hidden insights.\n",
    "\n",
    "#### Dataset Description:\n",
    "\n",
    "Distance: Distance travelled in Travel\n",
    "\n",
    "cab_type: Cab ride booked on Lyft or Uber\n",
    "\n",
    "time_stamp: Unix Timestamp booking time\n",
    "\n",
    "Destination: Destination in Boston (US)\n",
    "\n",
    "Source: Location of Booking in Boston (US)\n",
    "\n",
    "Price\n",
    "\n",
    "surge_multiplier: Different surge prices \t\n",
    "\n",
    "Id: Booking Id \n",
    "\n",
    "product_id: Product Id of Lyft and Uber\n",
    "\n",
    "Name: Name of Cab Rides\n",
    "\n",
    "Uber Rides – UberXL, Black, UberX, WAV, Black SUV, UberPool\n",
    "\n",
    "Lyft Rides – Shared, Lux, Lyft, Lux Black XL, Lyft XL, Lux Black \n",
    "\n",
    "Hint: Convert time_stamp into Date, Time & Weekdays for better insights. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Display all cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "\n",
    "path_data_cab = r'C:\\Users\\emmam\\Documents\\nlb\\data\\Uber_Lyft_Cab_rides.csv' \n",
    "path_data_weather = r'C:\\Users\\emmam\\Documents\\nlb\\data\\weather.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_data_cab)\n",
    "df.dropna(inplace=True)\n",
    "df['time_stamp_dt'] = pd.to_datetime(df['time_stamp'], unit='ms', origin='unix')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>destination</th>\n",
       "      <th>source</th>\n",
       "      <th>price</th>\n",
       "      <th>surge_multiplier</th>\n",
       "      <th>id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "      <th>time_stamp_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.03</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543203646318</td>\n",
       "      <td>Theatre District</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ef4771c2-c88d-4730-aaf7-a95751e9d27e</td>\n",
       "      <td>lyft_luxsuv</td>\n",
       "      <td>Lux Black XL</td>\n",
       "      <td>2018-11-26 03:40:46.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.30</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543203646319</td>\n",
       "      <td>Theatre District</td>\n",
       "      <td>South Station</td>\n",
       "      <td>18.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>00ea74ea-2c49-416c-bfc5-f7877025f6eb</td>\n",
       "      <td>6c84fd89-3f11-4782-9b50-97c468b19529</td>\n",
       "      <td>Black</td>\n",
       "      <td>2018-11-26 03:40:46.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.43</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543203646320</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>edfc7f44-97e1-48cd-930c-e4fe20e88ac8</td>\n",
       "      <td>lyft</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>2018-11-26 03:40:46.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.71</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543203646320</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Theatre District</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6172077a-22de-481b-aae2-b5763c87a6c4</td>\n",
       "      <td>6f72dfc5-27f1-42e8-84db-ccc7a75f6969</td>\n",
       "      <td>UberXL</td>\n",
       "      <td>2018-11-26 03:40:46.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.71</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543203646320</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Theatre District</td>\n",
       "      <td>19.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8682f9bf-5cc0-4dfc-b8fe-4e22070d1684</td>\n",
       "      <td>55c66225-fbe7-4fd5-9072-eab1ece5e23e</td>\n",
       "      <td>UberX</td>\n",
       "      <td>2018-11-26 03:40:46.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637971</th>\n",
       "      <td>2.40</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1545160510943</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b6710feb-4586-4c61-a2cf-cd4025ae8587</td>\n",
       "      <td>lyft_plus</td>\n",
       "      <td>Lyft XL</td>\n",
       "      <td>2018-12-18 19:15:10.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637972</th>\n",
       "      <td>2.40</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1545160510943</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a67a3e6e-7e21-4199-af07-b5532b125b67</td>\n",
       "      <td>lyft_luxsuv</td>\n",
       "      <td>Lux Black XL</td>\n",
       "      <td>2018-12-18 19:15:10.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637973</th>\n",
       "      <td>2.40</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1545160510943</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24712695-5b52-4886-955f-39c4bcd7c200</td>\n",
       "      <td>lyft_line</td>\n",
       "      <td>Shared</td>\n",
       "      <td>2018-12-18 19:15:10.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637974</th>\n",
       "      <td>2.40</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1545160510943</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12b81ef2-422b-4a39-9ef7-701c0f197cea</td>\n",
       "      <td>lyft</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>2018-12-18 19:15:10.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637975</th>\n",
       "      <td>2.40</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1545160510943</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11379a6c-1477-4501-ab22-d3a2165107d3</td>\n",
       "      <td>lyft_premier</td>\n",
       "      <td>Lux</td>\n",
       "      <td>2018-12-18 19:15:10.943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>637976 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance cab_type     time_stamp       destination  \\\n",
       "0           3.03     Lyft  1543203646318  Theatre District   \n",
       "1           1.30     Uber  1543203646319  Theatre District   \n",
       "2           2.43     Lyft  1543203646320       Beacon Hill   \n",
       "3           2.71     Uber  1543203646320            Fenway   \n",
       "4           2.71     Uber  1543203646320            Fenway   \n",
       "...          ...      ...            ...               ...   \n",
       "637971      2.40     Lyft  1545160510943       Beacon Hill   \n",
       "637972      2.40     Lyft  1545160510943       Beacon Hill   \n",
       "637973      2.40     Lyft  1545160510943       Beacon Hill   \n",
       "637974      2.40     Lyft  1545160510943       Beacon Hill   \n",
       "637975      2.40     Lyft  1545160510943       Beacon Hill   \n",
       "\n",
       "                         source  price  surge_multiplier  \\\n",
       "0             Boston University   34.0               1.0   \n",
       "1                 South Station   18.5               1.0   \n",
       "2       Northeastern University   10.5               1.0   \n",
       "3              Theatre District   32.0               1.0   \n",
       "4              Theatre District   19.5               1.0   \n",
       "...                         ...    ...               ...   \n",
       "637971  Northeastern University   16.5               1.0   \n",
       "637972  Northeastern University   32.5               1.0   \n",
       "637973  Northeastern University    7.0               1.0   \n",
       "637974  Northeastern University   10.5               1.0   \n",
       "637975  Northeastern University   16.5               1.0   \n",
       "\n",
       "                                          id  \\\n",
       "0       ef4771c2-c88d-4730-aaf7-a95751e9d27e   \n",
       "1       00ea74ea-2c49-416c-bfc5-f7877025f6eb   \n",
       "2       edfc7f44-97e1-48cd-930c-e4fe20e88ac8   \n",
       "3       6172077a-22de-481b-aae2-b5763c87a6c4   \n",
       "4       8682f9bf-5cc0-4dfc-b8fe-4e22070d1684   \n",
       "...                                      ...   \n",
       "637971  b6710feb-4586-4c61-a2cf-cd4025ae8587   \n",
       "637972  a67a3e6e-7e21-4199-af07-b5532b125b67   \n",
       "637973  24712695-5b52-4886-955f-39c4bcd7c200   \n",
       "637974  12b81ef2-422b-4a39-9ef7-701c0f197cea   \n",
       "637975  11379a6c-1477-4501-ab22-d3a2165107d3   \n",
       "\n",
       "                                  product_id          name  \\\n",
       "0                                lyft_luxsuv  Lux Black XL   \n",
       "1       6c84fd89-3f11-4782-9b50-97c468b19529         Black   \n",
       "2                                       lyft          Lyft   \n",
       "3       6f72dfc5-27f1-42e8-84db-ccc7a75f6969        UberXL   \n",
       "4       55c66225-fbe7-4fd5-9072-eab1ece5e23e         UberX   \n",
       "...                                      ...           ...   \n",
       "637971                             lyft_plus       Lyft XL   \n",
       "637972                           lyft_luxsuv  Lux Black XL   \n",
       "637973                             lyft_line        Shared   \n",
       "637974                                  lyft          Lyft   \n",
       "637975                          lyft_premier           Lux   \n",
       "\n",
       "                 time_stamp_dt  \n",
       "0      2018-11-26 03:40:46.318  \n",
       "1      2018-11-26 03:40:46.319  \n",
       "2      2018-11-26 03:40:46.320  \n",
       "3      2018-11-26 03:40:46.320  \n",
       "4      2018-11-26 03:40:46.320  \n",
       "...                        ...  \n",
       "637971 2018-12-18 19:15:10.943  \n",
       "637972 2018-12-18 19:15:10.943  \n",
       "637973 2018-12-18 19:15:10.943  \n",
       "637974 2018-12-18 19:15:10.943  \n",
       "637975 2018-12-18 19:15:10.943  \n",
       "\n",
       "[637976 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values('time_stamp_dt')#\n",
    "df = df.set_index(df['time_stamp_dt'])\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Back Bay',\n",
       " 'Beacon Hill',\n",
       " 'Boston University',\n",
       " 'Fenway',\n",
       " 'Financial District',\n",
       " 'Haymarket Square',\n",
       " 'North End',\n",
       " 'North Station',\n",
       " 'Northeastern University',\n",
       " 'South Station',\n",
       " 'Theatre District',\n",
       " 'West End'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'dataset location is Boston, MA, USA'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "{s for s in df['destination'].unique()}.union({s for s in df['source'].unique()}),\n",
    "\"dataset location is Boston, MA, USA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(637976, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 637976 entries, 0 to 637975\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   distance          637976 non-null  float64       \n",
      " 1   cab_type          637976 non-null  object        \n",
      " 2   time_stamp        637976 non-null  int64         \n",
      " 3   destination       637976 non-null  object        \n",
      " 4   source            637976 non-null  object        \n",
      " 5   price             637976 non-null  float64       \n",
      " 6   surge_multiplier  637976 non-null  float64       \n",
      " 7   id                637976 non-null  object        \n",
      " 8   product_id        637976 non-null  object        \n",
      " 9   name              637976 non-null  object        \n",
      " 10  time_stamp_dt     637976 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(3), int64(1), object(6)\n",
      "memory usage: 53.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2018-01-01',\n",
       " '2018-01-15',\n",
       " '2018-05-28',\n",
       " '2018-07-04',\n",
       " '2018-09-03',\n",
       " '2018-11-12',\n",
       " '2018-11-22',\n",
       " '2018-12-05',\n",
       " '2018-12-25']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'2018-11-26 03:40:46.318000'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Holidays\n",
    "\n",
    "#https://www.google.com/search?q=2018+usa+holidays&rlz=1C1CHBF_enUS847US847&oq=2018+usa+holidays&aqs=chrome..69i57j0i13i457j0i13l2j0i13i30l3j0i22i30.2664j0j7&sourceid=chrome&ie=UTF-8\n",
    "# United States/Public holidays (2018)\n",
    "# New Year's Day\tMon, Jan 1, 2018\n",
    "# Martin Luther King Jr. Day\tMon, Jan 15, 2018\n",
    "# Memorial Day\tMon, May 28, 2018\n",
    "# Independence Day\tWed, Jul 4, 2018\n",
    "# Labor Day\tMon, Sep 3, 2018\n",
    "# Veterans Day\tMon, Nov 12, 2018\n",
    "# Thanksgiving\tThu, Nov 22, 2018\n",
    "# George H. W. Bush Memorial Day\tWed, Dec 5, 2018\n",
    "# Christmas Day\tTue, Dec 25, 2018\n",
    "\n",
    "holidays=[\n",
    "    \"2018-01-01\",\n",
    "    \"2018-01-15\",\n",
    "    \"2018-05-28\",\n",
    "    \"2018-07-04\",\n",
    "    \"2018-09-03\",\n",
    "    \"2018-11-12\",\n",
    "    \"2018-11-22\",\n",
    "    \"2018-12-05\",\n",
    "    \"2018-12-25\",\n",
    "    ]\n",
    "\n",
    "holidays\n",
    "\n",
    "str(df['time_stamp_dt'][0])\n",
    "df['time_stamp_str'] = df['time_stamp_dt'].apply(lambda d: str(d)[:10])\n",
    "\n",
    "df[df['time_stamp_str'].isin(holidays)].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2018-11-26 03:40:46.318000'),\n",
       " Timestamp('2018-12-18 19:15:10.943000'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[df['time_stamp_str'].isin(holidays)]\n",
    "# df[df['time_stamp_str']==\"2018-05-28\"]\n",
    "# df['time_stamp_str'].sample()\n",
    "\n",
    "df['time_stamp_dt'].min(),df['time_stamp_dt'].max() # oops!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__array_priority__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__radd__',\n",
       " '__reduce__',\n",
       " '__reduce_cython__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rsub__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__setstate_cython__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_date_repr',\n",
       " '_repr_base',\n",
       " '_round',\n",
       " '_short_repr',\n",
       " '_time_repr',\n",
       " 'asm8',\n",
       " 'astimezone',\n",
       " 'ceil',\n",
       " 'combine',\n",
       " 'ctime',\n",
       " 'date',\n",
       " 'day',\n",
       " 'day_name',\n",
       " 'dayofweek',\n",
       " 'dayofyear',\n",
       " 'days_in_month',\n",
       " 'daysinmonth',\n",
       " 'dst',\n",
       " 'floor',\n",
       " 'fold',\n",
       " 'freq',\n",
       " 'freqstr',\n",
       " 'fromisocalendar',\n",
       " 'fromisoformat',\n",
       " 'fromordinal',\n",
       " 'fromtimestamp',\n",
       " 'hour',\n",
       " 'is_leap_year',\n",
       " 'is_month_end',\n",
       " 'is_month_start',\n",
       " 'is_quarter_end',\n",
       " 'is_quarter_start',\n",
       " 'is_year_end',\n",
       " 'is_year_start',\n",
       " 'isocalendar',\n",
       " 'isoformat',\n",
       " 'isoweekday',\n",
       " 'max',\n",
       " 'microsecond',\n",
       " 'min',\n",
       " 'minute',\n",
       " 'month',\n",
       " 'month_name',\n",
       " 'nanosecond',\n",
       " 'normalize',\n",
       " 'now',\n",
       " 'quarter',\n",
       " 'replace',\n",
       " 'resolution',\n",
       " 'round',\n",
       " 'second',\n",
       " 'strftime',\n",
       " 'strptime',\n",
       " 'time',\n",
       " 'timestamp',\n",
       " 'timetuple',\n",
       " 'timetz',\n",
       " 'to_datetime64',\n",
       " 'to_julian_date',\n",
       " 'to_numpy',\n",
       " 'to_period',\n",
       " 'to_pydatetime',\n",
       " 'today',\n",
       " 'toordinal',\n",
       " 'tz',\n",
       " 'tz_convert',\n",
       " 'tz_localize',\n",
       " 'tzinfo',\n",
       " 'tzname',\n",
       " 'utcfromtimestamp',\n",
       " 'utcnow',\n",
       " 'utcoffset',\n",
       " 'utctimetuple',\n",
       " 'value',\n",
       " 'week',\n",
       " 'weekday',\n",
       " 'weekofyear',\n",
       " 'year']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#working day rush hours\n",
    "\n",
    "dir(df['time_stamp_dt'][0])\n",
    "df['h'] = df['time_stamp_dt'].apply(lambda d: d.hour)\n",
    "\n",
    "rush_hours = [7,8,9,4,5,6] #basic way to partition time of day\n",
    "\n",
    "def is_rush_hours(df):\n",
    "    a = df['h'] in rush_hours\n",
    "    b = df['time_stamp_dt'].weekday() in [0,1,2,3,4]\n",
    "    return(all([a,b]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rush'] = df.apply(is_rush_hours, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1467550, 7464114, 8931664)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['rush']==True].size, df[df['rush']==False].size, df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*** proportion of sample in each surge category ***'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'inside rush hours'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.00    0.069123\n",
       "1.25    0.001238\n",
       "1.50    0.000575\n",
       "1.75    0.000236\n",
       "2.00    0.000234\n",
       "2.50    0.000021\n",
       "3.00    0.000001\n",
       "Name: surge_multiplier, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'outside rush hours'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.00    0.069072\n",
       "1.25    0.001242\n",
       "1.50    0.000566\n",
       "1.75    0.000278\n",
       "2.00    0.000254\n",
       "2.50    0.000016\n",
       "3.00    0.000001\n",
       "Name: surge_multiplier, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'seems working day rush hour does not significantly affect surge'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(\n",
    "    \"*** proportion of sample in each surge category ***\",\n",
    "    \"inside rush hours\",\n",
    "    df[df['rush']==True]['surge_multiplier'].value_counts()/df[df['rush']==True].size,\n",
    "    \"outside rush hours\",\n",
    "    df[df['rush']==False]['surge_multiplier'].value_counts()/ df[df['rush']==False].size,\n",
    "    \"seems working day rush hour does not significantly affect surge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(\n",
    "# list(zip(df['time_stamp_dt'][500:520],\n",
    "#          df['time_stamp_dt'][500:520].apply(lambda d : d.weekday()),\n",
    "#          df.iloc[500:520].index\n",
    "#          df['time_stamp_dt'][500:520].index\n",
    "#          df.iloc[500:520].apply(is_partytime),\n",
    "#         ))\n",
    "# )\n",
    "\n",
    "# df['time_stamp_dt'][546]\n",
    "# df.iloc[500:520].apply(is_partytime),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekday'] = df['time_stamp_dt'].apply(lambda d: d.weekday())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['time_stamp_dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df['time_stamp_dt'].max().weekday() # Monday == 0 ... Sunday == 6\n",
    "\n",
    "\n",
    "\n",
    "daywise_timedict = {3: [n for n in range(7, 13)],\n",
    "                    4: [n for n in range(8, 13)] + [0,1],\n",
    "                    5: [n for n in range(8, 13)] + [0,1,2,3],\n",
    "                    6: [0,1,2,3]\n",
    "                   }\n",
    "# display(\n",
    "# daywise_timedict.get(3),\n",
    "# )\n",
    "\n",
    "def is_partytime(df):\n",
    "    \"\"\"\n",
    "    function to identify traffic to bars and house parties\n",
    "    should include:\n",
    "        Thursday evening     ~7pm - 1am\n",
    "        Friday evening/night ~ 7pm - 3am\n",
    "        Saturday evening/night ~ 7pm - 3am\n",
    "    \"\"\"\n",
    "#     print(type(df))\n",
    "    daywise_timedict = {3: [n for n in range(19, 24)],\n",
    "                        4: [n for n in range(20, 24)] + [0,1],\n",
    "                        5: [n for n in range(20, 24)] + [0,1,2,3],\n",
    "                        6: [0,1,2,3]\n",
    "                       }\n",
    "#     wd = df['time_stamp_dt'].weekday()\n",
    "    wd = df['weekday']\n",
    "    l = daywise_timedict.get(wd)\n",
    "    \n",
    "    \n",
    "    if l == None:\n",
    "        return(False)\n",
    "#     print(wd, l, df['h'], df['h'] in l)\n",
    "    r = df['h'] in l\n",
    "    return(r)\n",
    "    \n",
    "\n",
    "\n",
    "# is_partytime(df.iloc[558])\n",
    "# type(df.iloc[546]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = df[(df['time_stamp_dt'] >= pd.to_datetime(\"2018-11-30\")) &\n",
    "#          (df['time_stamp_dt'] <= pd.to_datetime(\"2018-12-03\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.size/df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['partytime'] = df.apply(is_partytime, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12531505887368805"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['partytime']==True].size/df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*** proportion of sample in each surge category ***'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'inside party hours'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.00    0.060434\n",
       "1.25    0.001099\n",
       "1.50    0.000493\n",
       "1.75    0.000260\n",
       "2.00    0.000198\n",
       "2.50    0.000016\n",
       "Name: surge_multiplier, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'outside party hours'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.00    0.060447\n",
       "1.25    0.001084\n",
       "1.50    0.000497\n",
       "1.75    0.000234\n",
       "2.00    0.000222\n",
       "2.50    0.000015\n",
       "3.00    0.000001\n",
       "Name: surge_multiplier, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'seems party hours do not significantly affect surge'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(\n",
    "    \"*** proportion of sample in each surge category ***\",\n",
    "    \"inside party hours\",\n",
    "    df[df['partytime']==True]['surge_multiplier'].value_counts()/df[df['partytime']==True].size,\n",
    "    \"outside party hours\",\n",
    "    df[df['partytime']==False]['surge_multiplier'].value_counts()/ df[df['partytime']==False].size,\n",
    "    \"seems party hours do not significantly affect surge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.00    617001\n",
       "1.25     11085\n",
       "1.50      5065\n",
       "1.75      2420\n",
       "2.00      2239\n",
       "2.50       154\n",
       "3.00        12\n",
       "Name: surge_multiplier, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['surge_multiplier'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "surge_multiplier    1.000000\n",
       "price               0.240458\n",
       "distance            0.025946\n",
       "time_stamp          0.000611\n",
       "h                  -0.000067\n",
       "partytime          -0.000192\n",
       "weekday            -0.001600\n",
       "rush               -0.002226\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr().unstack()['surge_multiplier'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "partytime           1.000000\n",
       "weekday             0.311052\n",
       "time_stamp          0.097542\n",
       "h                   0.053722\n",
       "price               0.001044\n",
       "distance            0.000150\n",
       "surge_multiplier   -0.000192\n",
       "rush               -0.167835\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr().unstack()['partytime'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rush                1.000000\n",
       "time_stamp          0.005338\n",
       "price              -0.001381\n",
       "distance           -0.001949\n",
       "surge_multiplier   -0.002226\n",
       "partytime          -0.167835\n",
       "weekday            -0.209858\n",
       "h                  -0.326996\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr().unstack()['rush'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "temp             0\n",
       "location         0\n",
       "clouds           0\n",
       "pressure         0\n",
       "rain          5382\n",
       "time_stamp       0\n",
       "humidity         0\n",
       "wind             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w= pd.read_csv(path_data_weather)\n",
    "df_w.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rain</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3892</th>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5060</th>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215</th>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091</th>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3345</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5635</th>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3372</th>\n",
       "      <td>0.0320</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.0599</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>0.1207</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5139</th>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5376</th>\n",
       "      <td>0.1561</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>0.1672</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5374</th>\n",
       "      <td>0.1816</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4778</th>\n",
       "      <td>0.2195</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3028</th>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720</th>\n",
       "      <td>0.5337</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rain  humidity\n",
       "5238  0.0031      0.91\n",
       "1918  0.0040      0.91\n",
       "2040  0.0050      0.97\n",
       "1076  0.0052      0.91\n",
       "3892  0.0080      0.93\n",
       "5060  0.0090      0.93\n",
       "4215  0.0130      0.91\n",
       "3091  0.0183      0.86\n",
       "3345  0.0210      0.90\n",
       "5635  0.0250      0.93\n",
       "3372  0.0320      0.88\n",
       "994   0.0599      0.84\n",
       "3574  0.1207      0.89\n",
       "5139  0.1495      0.91\n",
       "5376  0.1561      0.91\n",
       "5432  0.1672      0.91\n",
       "5374  0.1816      0.91\n",
       "4778  0.2195      0.87\n",
       "3028  0.2350      0.89\n",
       "3720  0.5337      0.91"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_w['time_stamp_dt'] = pd.to_datetime(df_w['time_stamp'], unit='ms', origin='unix')\n",
    "df_w['time_stamp_dt'] = pd.to_datetime(df_w['time_stamp'], unit='s', origin='unix')\n",
    "df_w[df_w['rain'].notna()].sample(20)[['rain','humidity']].sort_values('rain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "rain_imputer = IterativeImputer()\n",
    "\n",
    "\n",
    "# rain_imputer.fit(df_w[['temp','clouds','pressure','humidity','wind']])\n",
    "# df_w[]rain_imputer.transform()\n",
    "# imp.fit([[1, 2], [3, 6], [4, 8], [np.nan, 3], [7, np.nan]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterativeImputer()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rain_imputer.fit(df_w[df_w['rain'].notna()][['temp','clouds','pressure','humidity','wind','rain']])\n",
    "\n",
    "# rain_imputer.fit(df_w[['temp','clouds','pressure','humidity','wind','rain']])\n",
    "\n",
    "# rain_imputer.transform(df_w[df_w['rain'].isna()]['rain'])\n",
    "\n",
    "\n",
    "x = df_w[df_w['rain'].notna()][['temp','clouds','pressure','humidity','wind','rain']]\n",
    "rain_imputer.fit(x)\n",
    "\n",
    "y = rain_imputer.transform(df_w[['temp','clouds','pressure','humidity','wind','rain']] )\n",
    "y = [i[-1] for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(-0.006713895047982319, -0.0036352469364608897)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.05765234899328859, 0.01485)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(y).sum()\n",
    "np.mean(y), np.median(y)\n",
    "np.nanmean(df_w['rain']), np.nanmedian(df_w['rain'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNNImputer(n_neighbors=95, weights='distance')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.02504977094982021, 0.014301475551852193)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.05765234899328859, 0.01485)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'closest imputation?'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain_imputer = KNNImputer(weights='distance', n_neighbors=95)\n",
    "\n",
    "\n",
    "x = df_w[df_w['rain'].notna()][['temp','clouds','pressure','humidity','wind','rain']]\n",
    "rain_imputer.fit(x)\n",
    "\n",
    "y = rain_imputer.transform(df_w[['temp','clouds','pressure','humidity','wind','rain']] )\n",
    "y = [i[-1] for i in y]\n",
    "\n",
    "np.isnan(y).sum()\n",
    "np.mean(y), np.median(y)\n",
    "np.nanmean(df_w['rain']), np.nanmedian(df_w['rain'])\n",
    "'closest imputation?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w['rain'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "temp             0\n",
       "location         0\n",
       "clouds           0\n",
       "pressure         0\n",
       "rain             0\n",
       "time_stamp       0\n",
       "humidity         0\n",
       "wind             0\n",
       "time_stamp_dt    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2018-11-26 03:40:44'), Timestamp('2018-12-18 18:45:02'))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w['time_stamp_dt'].min(), df_w['time_stamp_dt'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2018-12-16 23\n",
       "1       2018-12-16 23\n",
       "2       2018-12-16 23\n",
       "3       2018-12-16 23\n",
       "4       2018-12-16 23\n",
       "            ...      \n",
       "6271    2018-12-03 06\n",
       "6272    2018-12-03 06\n",
       "6273    2018-12-03 06\n",
       "6274    2018-12-03 06\n",
       "6275    2018-12-03 06\n",
       "Name: time_stamp_str, Length: 6276, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ts_hr = lambda d: str(d)[:13] # If set to 15th ix (date time to tens place of minutes) I get many extra rows on df.merge() even with how='left'/'inner'!!!\n",
    "df['time_stamp_str'] = df['time_stamp_dt'].apply(ts_hr)\n",
    "df_w['time_stamp_str'] = df_w['time_stamp_dt'].apply(ts_hr)\n",
    "df_w['time_stamp_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w['source'] = df_w['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6276 entries, 0 to 6275\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   temp            6276 non-null   float64       \n",
      " 1   location        6276 non-null   object        \n",
      " 2   clouds          6276 non-null   float64       \n",
      " 3   pressure        6276 non-null   float64       \n",
      " 4   rain            6276 non-null   float64       \n",
      " 5   time_stamp      6276 non-null   int64         \n",
      " 6   humidity        6276 non-null   float64       \n",
      " 7   wind            6276 non-null   float64       \n",
      " 8   time_stamp_dt   6276 non-null   datetime64[ns]\n",
      " 9   time_stamp_str  6276 non-null   object        \n",
      " 10  source          6276 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(6), int64(1), object(3)\n",
      "memory usage: 539.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_w.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfj = df.merge(df_w, on=['time_stamp_str', 'source'], how='left', copy=False)\n",
    "# dfj = df.merge(df_w, on=['time_stamp_str', 'source'], how='left')\n",
    "# dfj = df.merge(df_w, on=['source', 'time_stamp_str'], how='left')\n",
    "\n",
    "# dfj = df.merge(df_w, left_on=['source', 'time_stamp_str'], \n",
    "#                right_on=['location', 'time_stamp_str'], how='left')\n",
    "\n",
    "dfj = df.merge(df_w, left_on=['source', 'time_stamp_str'], \n",
    "               right_on=['location', 'time_stamp_str'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>time_stamp_x</th>\n",
       "      <th>destination</th>\n",
       "      <th>source_x</th>\n",
       "      <th>price</th>\n",
       "      <th>surge_multiplier</th>\n",
       "      <th>id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "      <th>...</th>\n",
       "      <th>temp</th>\n",
       "      <th>location</th>\n",
       "      <th>clouds</th>\n",
       "      <th>pressure</th>\n",
       "      <th>rain</th>\n",
       "      <th>time_stamp_y</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "      <th>time_stamp_dt_y</th>\n",
       "      <th>source_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.03</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543203646318</td>\n",
       "      <td>Theatre District</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>ef4771c2-c88d-4730-aaf7-a95751e9d27e</td>\n",
       "      <td>lyft_luxsuv</td>\n",
       "      <td>Lux Black XL</td>\n",
       "      <td>...</td>\n",
       "      <td>41.07</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1014.39</td>\n",
       "      <td>0.011524</td>\n",
       "      <td>1543203645</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.36</td>\n",
       "      <td>2018-11-26 03:40:45</td>\n",
       "      <td>Boston University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.46</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543203646359</td>\n",
       "      <td>Financial District</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>47.5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3b5af7f6-40ba-42f2-a218-971dcba4f33e</td>\n",
       "      <td>lyft_premier</td>\n",
       "      <td>Lux</td>\n",
       "      <td>...</td>\n",
       "      <td>41.07</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1014.39</td>\n",
       "      <td>0.011524</td>\n",
       "      <td>1543203645</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.36</td>\n",
       "      <td>2018-11-26 03:40:45</td>\n",
       "      <td>Boston University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.46</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543203646359</td>\n",
       "      <td>Financial District</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>62.5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1178f52c-9bd4-4b28-a03a-d94e68bfafa3</td>\n",
       "      <td>lyft_lux</td>\n",
       "      <td>Lux Black</td>\n",
       "      <td>...</td>\n",
       "      <td>41.07</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1014.39</td>\n",
       "      <td>0.011524</td>\n",
       "      <td>1543203645</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.36</td>\n",
       "      <td>2018-11-26 03:40:45</td>\n",
       "      <td>Boston University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.06</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543203646551</td>\n",
       "      <td>West End</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>22.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>e4d3df16-8b2b-4748-bf2b-f3b4e62c0ba2</td>\n",
       "      <td>lyft_premier</td>\n",
       "      <td>Lux</td>\n",
       "      <td>...</td>\n",
       "      <td>41.07</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1014.39</td>\n",
       "      <td>0.011524</td>\n",
       "      <td>1543203645</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.36</td>\n",
       "      <td>2018-11-26 03:40:45</td>\n",
       "      <td>Boston University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.06</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543203646551</td>\n",
       "      <td>West End</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5f3ee457-8e98-4b4b-9582-e6bc3a3ad0e7</td>\n",
       "      <td>lyft</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>...</td>\n",
       "      <td>41.07</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1014.39</td>\n",
       "      <td>0.011524</td>\n",
       "      <td>1543203645</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.36</td>\n",
       "      <td>2018-11-26 03:40:45</td>\n",
       "      <td>Boston University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164991</th>\n",
       "      <td>3.00</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1545159307819</td>\n",
       "      <td>Theatre District</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>59e0e8de-17ef-4421-a5f9-4b9df2ba48e5</td>\n",
       "      <td>lyft_line</td>\n",
       "      <td>Shared</td>\n",
       "      <td>...</td>\n",
       "      <td>30.96</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1012.35</td>\n",
       "      <td>0.021725</td>\n",
       "      <td>1545158702</td>\n",
       "      <td>0.45</td>\n",
       "      <td>12.93</td>\n",
       "      <td>2018-12-18 18:45:02</td>\n",
       "      <td>Boston University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164992</th>\n",
       "      <td>2.93</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1545159309992</td>\n",
       "      <td>Theatre District</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>f8d72e65-65c5-4cc0-ba38-aaec932f0c33</td>\n",
       "      <td>lyft_premier</td>\n",
       "      <td>Lux</td>\n",
       "      <td>...</td>\n",
       "      <td>30.96</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1012.35</td>\n",
       "      <td>0.021725</td>\n",
       "      <td>1545158702</td>\n",
       "      <td>0.45</td>\n",
       "      <td>12.93</td>\n",
       "      <td>2018-12-18 18:45:02</td>\n",
       "      <td>Boston University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164993</th>\n",
       "      <td>2.40</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1545159311401</td>\n",
       "      <td>Theatre District</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>f67fd589-a11f-4556-a748-1bbe7139e301</td>\n",
       "      <td>997acbb5-e102-41e1-b155-9df7de0a73f2</td>\n",
       "      <td>UberPool</td>\n",
       "      <td>...</td>\n",
       "      <td>30.96</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1012.35</td>\n",
       "      <td>0.021725</td>\n",
       "      <td>1545158702</td>\n",
       "      <td>0.45</td>\n",
       "      <td>12.93</td>\n",
       "      <td>2018-12-18 18:45:02</td>\n",
       "      <td>Boston University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164994</th>\n",
       "      <td>1.53</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1545159312093</td>\n",
       "      <td>Back Bay</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>d9fe2fb0-a346-4300-bcbf-565b33e05c35</td>\n",
       "      <td>lyft_plus</td>\n",
       "      <td>Lyft XL</td>\n",
       "      <td>...</td>\n",
       "      <td>30.96</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1012.35</td>\n",
       "      <td>0.021725</td>\n",
       "      <td>1545158702</td>\n",
       "      <td>0.45</td>\n",
       "      <td>12.93</td>\n",
       "      <td>2018-12-18 18:45:02</td>\n",
       "      <td>Boston University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164995</th>\n",
       "      <td>1.53</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1545159312093</td>\n",
       "      <td>Back Bay</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>b002e95b-47f1-4836-bada-a4ff0a6a46ef</td>\n",
       "      <td>lyft_lux</td>\n",
       "      <td>Lux Black</td>\n",
       "      <td>...</td>\n",
       "      <td>30.96</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1012.35</td>\n",
       "      <td>0.021725</td>\n",
       "      <td>1545158702</td>\n",
       "      <td>0.45</td>\n",
       "      <td>12.93</td>\n",
       "      <td>2018-12-18 18:45:02</td>\n",
       "      <td>Boston University</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1164996 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         distance cab_type   time_stamp_x         destination  \\\n",
       "0            3.03     Lyft  1543203646318    Theatre District   \n",
       "1            4.46     Lyft  1543203646359  Financial District   \n",
       "2            4.46     Lyft  1543203646359  Financial District   \n",
       "3            3.06     Lyft  1543203646551            West End   \n",
       "4            3.06     Lyft  1543203646551            West End   \n",
       "...           ...      ...            ...                 ...   \n",
       "1164991      3.00     Lyft  1545159307819    Theatre District   \n",
       "1164992      2.93     Lyft  1545159309992    Theatre District   \n",
       "1164993      2.40     Uber  1545159311401    Theatre District   \n",
       "1164994      1.53     Lyft  1545159312093            Back Bay   \n",
       "1164995      1.53     Lyft  1545159312093            Back Bay   \n",
       "\n",
       "                  source_x  price  surge_multiplier  \\\n",
       "0        Boston University   34.0              1.00   \n",
       "1        Boston University   47.5              1.75   \n",
       "2        Boston University   62.5              1.75   \n",
       "3        Boston University   22.5              1.00   \n",
       "4        Boston University   10.5              1.00   \n",
       "...                    ...    ...               ...   \n",
       "1164991  Boston University    7.0              1.00   \n",
       "1164992  Boston University   34.0              1.75   \n",
       "1164993  Boston University   10.0              1.00   \n",
       "1164994  Boston University   11.0              1.00   \n",
       "1164995  Boston University   16.5              1.00   \n",
       "\n",
       "                                           id  \\\n",
       "0        ef4771c2-c88d-4730-aaf7-a95751e9d27e   \n",
       "1        3b5af7f6-40ba-42f2-a218-971dcba4f33e   \n",
       "2        1178f52c-9bd4-4b28-a03a-d94e68bfafa3   \n",
       "3        e4d3df16-8b2b-4748-bf2b-f3b4e62c0ba2   \n",
       "4        5f3ee457-8e98-4b4b-9582-e6bc3a3ad0e7   \n",
       "...                                       ...   \n",
       "1164991  59e0e8de-17ef-4421-a5f9-4b9df2ba48e5   \n",
       "1164992  f8d72e65-65c5-4cc0-ba38-aaec932f0c33   \n",
       "1164993  f67fd589-a11f-4556-a748-1bbe7139e301   \n",
       "1164994  d9fe2fb0-a346-4300-bcbf-565b33e05c35   \n",
       "1164995  b002e95b-47f1-4836-bada-a4ff0a6a46ef   \n",
       "\n",
       "                                   product_id          name  ...   temp  \\\n",
       "0                                 lyft_luxsuv  Lux Black XL  ...  41.07   \n",
       "1                                lyft_premier           Lux  ...  41.07   \n",
       "2                                    lyft_lux     Lux Black  ...  41.07   \n",
       "3                                lyft_premier           Lux  ...  41.07   \n",
       "4                                        lyft          Lyft  ...  41.07   \n",
       "...                                       ...           ...  ...    ...   \n",
       "1164991                             lyft_line        Shared  ...  30.96   \n",
       "1164992                          lyft_premier           Lux  ...  30.96   \n",
       "1164993  997acbb5-e102-41e1-b155-9df7de0a73f2      UberPool  ...  30.96   \n",
       "1164994                             lyft_plus       Lyft XL  ...  30.96   \n",
       "1164995                              lyft_lux     Lux Black  ...  30.96   \n",
       "\n",
       "                  location  clouds  pressure      rain  time_stamp_y  \\\n",
       "0        Boston University    0.86   1014.39  0.011524    1543203645   \n",
       "1        Boston University    0.86   1014.39  0.011524    1543203645   \n",
       "2        Boston University    0.86   1014.39  0.011524    1543203645   \n",
       "3        Boston University    0.86   1014.39  0.011524    1543203645   \n",
       "4        Boston University    0.86   1014.39  0.011524    1543203645   \n",
       "...                    ...     ...       ...       ...           ...   \n",
       "1164991  Boston University    0.00   1012.35  0.021725    1545158702   \n",
       "1164992  Boston University    0.00   1012.35  0.021725    1545158702   \n",
       "1164993  Boston University    0.00   1012.35  0.021725    1545158702   \n",
       "1164994  Boston University    0.00   1012.35  0.021725    1545158702   \n",
       "1164995  Boston University    0.00   1012.35  0.021725    1545158702   \n",
       "\n",
       "         humidity   wind     time_stamp_dt_y           source_y  \n",
       "0            0.92   1.36 2018-11-26 03:40:45  Boston University  \n",
       "1            0.92   1.36 2018-11-26 03:40:45  Boston University  \n",
       "2            0.92   1.36 2018-11-26 03:40:45  Boston University  \n",
       "3            0.92   1.36 2018-11-26 03:40:45  Boston University  \n",
       "4            0.92   1.36 2018-11-26 03:40:45  Boston University  \n",
       "...           ...    ...                 ...                ...  \n",
       "1164991      0.45  12.93 2018-12-18 18:45:02  Boston University  \n",
       "1164992      0.45  12.93 2018-12-18 18:45:02  Boston University  \n",
       "1164993      0.45  12.93 2018-12-18 18:45:02  Boston University  \n",
       "1164994      0.45  12.93 2018-12-18 18:45:02  Boston University  \n",
       "1164995      0.45  12.93 2018-12-18 18:45:02  Boston University  \n",
       "\n",
       "[1164996 rows x 26 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1164996, 26), (637976, 16))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "distance            0\n",
       "cab_type            0\n",
       "time_stamp_x        0\n",
       "destination         0\n",
       "source_x            0\n",
       "price               0\n",
       "surge_multiplier    0\n",
       "id                  0\n",
       "product_id          0\n",
       "name                0\n",
       "time_stamp_dt_x     0\n",
       "time_stamp_str      0\n",
       "h                   0\n",
       "rush                0\n",
       "weekday             0\n",
       "partytime           0\n",
       "temp                0\n",
       "location            0\n",
       "clouds              0\n",
       "pressure            0\n",
       "rain                0\n",
       "time_stamp_y        0\n",
       "humidity            0\n",
       "wind                0\n",
       "time_stamp_dt_y     0\n",
       "source_y            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfj.shape, df.shape\n",
    "dfj.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfj = dfj.drop_duplicates(subset='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((635242, 26), (637976, 16))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "distance            0\n",
       "cab_type            0\n",
       "time_stamp_x        0\n",
       "destination         0\n",
       "source_x            0\n",
       "price               0\n",
       "surge_multiplier    0\n",
       "id                  0\n",
       "product_id          0\n",
       "name                0\n",
       "time_stamp_dt_x     0\n",
       "time_stamp_str      0\n",
       "h                   0\n",
       "rush                0\n",
       "weekday             0\n",
       "partytime           0\n",
       "temp                0\n",
       "location            0\n",
       "clouds              0\n",
       "pressure            0\n",
       "rain                0\n",
       "time_stamp_y        0\n",
       "humidity            0\n",
       "wind                0\n",
       "time_stamp_dt_y     0\n",
       "source_y            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfj.shape, df.shape\n",
    "dfj.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "surge_multiplier    1.000000\n",
       "price               0.240325\n",
       "distance            0.025830\n",
       "pressure            0.002912\n",
       "rush                0.002296\n",
       "clouds              0.001996\n",
       "temp                0.001635\n",
       "rain                0.001623\n",
       "weekday             0.001607\n",
       "wind                0.001286\n",
       "humidity            0.001253\n",
       "time_stamp_x        0.000769\n",
       "time_stamp_y        0.000769\n",
       "partytime           0.000180\n",
       "h                   0.000108\n",
       "dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "surge_multiplier    1.000000\n",
       "price               0.240325\n",
       "distance            0.025830\n",
       "pressure           -0.002912\n",
       "rush               -0.002296\n",
       "clouds             -0.001996\n",
       "temp               -0.001635\n",
       "rain               -0.001623\n",
       "weekday            -0.001607\n",
       "wind                0.001286\n",
       "humidity           -0.001253\n",
       "time_stamp_x        0.000769\n",
       "time_stamp_y        0.000769\n",
       "partytime          -0.000180\n",
       "h                   0.000108\n",
       "dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfj.corr().abs().unstack()['surge_multiplier'].sort_values(ascending=False)\n",
    "\n",
    "dfj.corr().unstack()['surge_multiplier'].sort_values(ascending=False, key=lambda i: abs(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strongest correlates of surge (rain is imputed)'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "distance    0.025830\n",
       "pressure   -0.002912\n",
       "rush       -0.002296\n",
       "clouds     -0.001996\n",
       "temp       -0.001635\n",
       "rain       -0.001623\n",
       "dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"strongest correlates of surge (rain is imputed)\"\n",
    "dfj.corr().unstack()['surge_multiplier'][['distance', 'pressure', 'rush', 'clouds', 'temp', 'rain']].sort_values(ascending=False, key=lambda i: abs(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
